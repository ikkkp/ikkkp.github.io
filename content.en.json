{"pages":[{"title":"About Me","text":"Writing: A Soliloquy of the Soul“Writing is a soliloquy of the soul, a flow of the spirit.” - Wang Xiaobo I am ikkkp. In fact, the idea of creating my own personal website and sharing things I love on it has been in my mind for quite some time. The reason I write might not be very complicated. Words are my bridge to the world, a tool with which I think, feel, and touch life. Writing, for me, is a way to find companionship in solitude, a beacon of direction in moments of confusion. Words annotate life, and writing reveals the inner self. In this noisy world, writing has found me a sanctuary, a moment of tranquility. Writing allows me to think more clearly, to understand myself more profoundly. Every time I transform my thoughts into words, it’s like giving my soul a baptism, a process that helps me comprehend the depths of my inner world. Writing is also my way of connecting with others. Through words, I can convey my thoughts, share my experiences, and build profound emotional bonds with others. In the ocean of words, we can sail without constraints, exploring endless possibilities.","link":"/en/abouts/index.html"}],"posts":[{"title":"301/302 Redirection","text":"IntroductionWhen configuring redirects on a website, especially in the following scenarios, issues can arise: Redirecting from HTTP to HTTPS: Suppose you’ve set up an SSL certificate to upgrade your website from HTTP to HTTPS. If problems occur during this process, rendering the site inaccessible, you might consider reverting to the HTTP version. However, the challenge arises once a permanent 301 redirection is in place. Even if you remove the redirection on the server, browsers retain this information. Consequently, users’ browsers continue to enforce the HTTPS redirection, preventing them from accessing the HTTP version. Changing the Website Domain: When migrating a website from one domain (such as old-domain.com) to another (such as new-domain.com), a permanent 301 redirection is often employed. This informs search engines and browsers that the site has permanently moved to a new domain. However, if complications arise during this process, you may wish to undo the redirection, allowing users to access the old domain again. Unfortunately, due to browser hard caching of 301 redirections, users become permanently redirected to the new domain, unable to revisit the old one. To avoid such situations, it is advisable to use a temporary 302 redirection initially, ensuring everything functions correctly. Unlike a 301 redirection, a 302 redirection is not permanently cached by browsers. This means that if necessary, you can revert the redirection without users being permanently locked into the new URL. This approach eliminates the need for users to manually clear their browser caches, enhancing the overall user experience. 301 Redirection: Indicates that a resource (page) has permanently moved to a new location. The client&#x2F;browser should not attempt to request the original location but use the new location from now on. 302 Redirection: Indicates that the resource is temporarily located elsewhere, and the client&#x2F;browser should continue requesting the original URL. A 301 redirection is permanent, meaning that even if removed from the server, browsers will perpetually redirect resources to the new domain or HTTPS due to hard caching. On the other hand, a 302 redirection is not hard-cached by browsers. If you remove the redirection from your server (website), you can still access the old version. Clearing 301&#x2F;302 redirection cache typically involves clearing browser cache or the operating system’s DNS cache. Here’s how to do it on different platforms: Clearing Browser Cache (Applicable to Windows, macOS, Linux)Google Chrome: Open the Chrome browser. Click the three vertical dots in the upper right corner and select “More tools.” Choose “Clear browsing data.” In the popup window, select the “Advanced” tab. Set the time range to “All time.” Check the “Cached images and files” option. Click the “Clear data” button. Mozilla Firefox: Open the Firefox browser. Click the three horizontal lines in the upper right corner and select “Privacy &amp; Security.” In the “Cookies and Site Data” section, click “Clear Data.” Ensure the “Cache” option is checked. Click “Clear.” Microsoft Edge: Open the Edge browser. Click the three horizontal dots in the upper right corner and select “Settings.” Scroll down and click “View advanced settings.” In the “Privacy and services” section, click “Clear browsing data.” Check the “Cached images and files” option. Click the “Clear” button. Clearing Operating System’s DNS Cache (Applicable to Windows, macOS)Windows: Open Command Prompt (search for “cmd” in the Start menu and open it). Enter the following command and press Enter:ipconfig &#x2F;flushdns macOS: Open Terminal (find it in Applications &gt; Utilities folder). Enter the following command and press Enter:sudo dscacheutil -flushcache Then enter your administrator password and press Enter again. Please note that clearing browser cache might lead to loss of login sessions on websites. Ensure you have backed up essential information in case you need to log in again.","link":"/2023/10/28/en/301-302-Redirection/"},{"title":"Webpack Performance Optimization-1","text":"IntroductionLet’s talk about why optimization is necessary. If your project is small and builds quickly, you might not need to worry too much about performance optimization. However, as your project grows with more pages, features, and business logic, the build time of webpack, the underlying build tool, also increases. At this point, optimizing performance becomes crucial. Webpack offers various avenues for performance optimization, which can be broadly categorized into two areas: Optimization One: Optimizing the built result for production, focusing on performance during deployment (e.g., code splitting, reducing bundle size, using CDN servers, etc.).Optimization Two: Optimizing build speed for development or production build, enhancing the speed of the build process (e.g., using exclusion, cache loaders, etc.).The performance during production directly affects user experience, whereas build time is closely related to developers’ daily workflow. If the local development server or production build takes too long, it significantly hampers productivity. Performance Optimization - Code SplittingCode splitting is a critical feature in webpack: Its primary purpose is to separate code into different bundles, which can be loaded on demand or in parallel.By default, all JavaScript code (business logic, third-party dependencies, and modules not immediately used) is loaded on the initial page load, impacting the loading speed.Code splitting allows creating smaller bundles and controlling resource loading priorities, thereby enhancing code loading performance. Webpack provides three common approaches to code splitting: Entry Points: Manually splitting code using entry configuration Preventing Duplication: Avoiding duplicate code using Entry Dependencies or SplitChunksPlugin Dynamic Imports: Splitting code using inline functions in modules Optimizing Entry Points - Entry DependenciesWhen a project has multiple entry points, there might be issues with duplicate dependencies. Some modules might be referenced in multiple entry points, causing redundancy in the final output, increasing the output file size. module.exports = &#123; entry: &#123; page1: &#123; import: './src/page1.js', dependOn: 'shared', &#125;, page2: &#123; import: './src/page2.js', dependOn: 'shared', &#125;, shared: './src/shared.js', &#125;, output: &#123; filename: '[name].bundle.js', path: __dirname + '/dist', &#125;, &#125;; Dynamic ImportsDynamic imports are a technique in webpack for lazy loading, allowing modules to load asynchronously at runtime instead of bundling all modules into a large initial file. This approach improves the initial loading speed and reduces the initial bundle size. const path = require('path'); module.exports = &#123; entry: &#123; main: './src/index.js', &#125;, output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist'), publicPath: '/', &#125;, module: &#123; rules: [ // Add your loader rules here ], &#125;, optimization: &#123; splitChunks: &#123; chunks: 'all', &#125;, &#125;, &#125;; In the above configuration, code splitting is achieved using optimization.splitChunks with the option chunks: &#39;all&#39;. Then, dynamic imports can be used in the code like this: // Dynamically import modules where needed const loadModule = () => import('./Module'); loadModule().then(module => &#123; // Use the loaded module &#125;); Webpack will split the modules imported using import() into separate files. These files will be loaded asynchronously when needed during runtime. Custom Bundle Splitting - SplitChunksBundle splitting is an optimization strategy that allows breaking down code into smaller pieces, enabling faster content display during loading. Webpack provides various strategies for bundle splitting, one of which involves using the SplitChunksPlugin plugin. This strategy is known as splitChunks. module.exports = &#123; // ...other configurations optimization: &#123; splitChunks: &#123; chunks: 'all', minSize: 30000, // Minimum size of the module before splitting minChunks: 1, // Minimum number of times a module should be duplicated before splitting maxAsyncRequests: 5, // Maximum number of parallel requests when loading modules on demand maxInitialRequests: 3, // Maximum number of parallel requests at an entry point automaticNameDelimiter: '~', name: true, cacheGroups: &#123; vendors: &#123; test: /[\\\\/]node_modules[\\\\/]/, priority: -10, reuseExistingChunk: true, &#125;, default: &#123; minChunks: 2, priority: -20, reuseExistingChunk: true, &#125;, &#125;, &#125;, &#125;, &#125;; For more information, refer to the webpack-split-chunks-plugin documentation. Performance Optimization - CDNCDN, or Content Delivery Network, refers to a network of interconnected servers strategically placed to deliver content to users efficiently. It ensures faster and more reliable delivery of resources such as music, images, videos, applications, and other files by utilizing servers closest to each user, providing high performance, scalability, and low-cost content delivery. In development, CDN is typically used in two ways: All static resources are bundled and stored on a CDN server, and users load resources exclusively through the CDN. Some third-party resources are hosted on CDN servers. Utilizing a Content Delivery Network (CDN) is a highly effective performance optimization strategy, especially within Webpack. CDN accelerates website loading speed, reduces server load, and enhances user experience. Here’s how you can configure and use CDN in Webpack: Using CDN for Third-Party LibrariesIntegrate third-party libraries used in your project (such as React, Vue, jQuery, etc.) through CDN links directly in the HTML file: &lt;script src=\"https://cdn.jsdelivr.net/npm/react@version/dist/react.min.js\">&lt;/script> &lt;script src=\"https://cdn.jsdelivr.net/npm/react-dom@version/dist/react-dom.min.js\">&lt;/script> Configuring Externals in WebpackIn your Webpack configuration, utilize the externals field to inform Webpack about externally referenced modules that shouldn’t be bundled: module.exports = &#123; // ...other configurations externals: &#123; react: 'React', 'react-dom': 'ReactDOM', &#125;, &#125;; Then, include the CDN links in the HTML file using script tags: &lt;script src=\"https://cdn.jsdelivr.net/npm/react@version/dist/react.min.js\">&lt;/script> &lt;script src=\"https://cdn.jsdelivr.net/npm/react-dom@version/dist/react-dom.min.js\">&lt;/script> Configuring CDN’s publicPathIn the Webpack output field, set the publicPath to specify the URL prefix for resource imports, typically set to the CDN’s address: module.exports = &#123; // ...other configurations output: &#123; // ...other output configurations publicPath: 'https://cdn.example.com/', &#125;, &#125;; This way, during Webpack build, all resource paths will be prefixed with the CDN’s address. Performance Optimization - Extracting CSS FilesExtracting CSS files from JavaScript bundles is a common performance optimization strategy. This approach reduces the size of JavaScript files, speeds up page loading, and allows browsers to download CSS and JavaScript files in parallel, enhancing loading performance. In Webpack, you can achieve this using the mini-css-extract-plugin plugin. Webpack ConfigurationIn your Webpack configuration file, include the mini-css-extract-plugin plugin and configure the module.rules to handle CSS files: const MiniCssExtractPlugin = require('mini-css-extract-plugin'); module.exports = &#123; // ...other configurations module: &#123; rules: [ &#123; test: /\\.css$/, use: [ MiniCssExtractPlugin.loader, 'css-loader', // Additional CSS loaders like postcss-loader and sass-loader can be added here ], &#125;, ], &#125;, plugins: [ new MiniCssExtractPlugin(&#123; filename: 'styles.css', // Filename for the extracted CSS file &#125;), ], &#125;; Including CSS FilesIn your JavaScript files or entry point file, import the CSS file: import './styles.css'; Alternatively, in the HTML file, use the link tag to include the extracted CSS file: &lt;link rel=\"stylesheet\" href=\"styles.css\"> Performance Optimization - Bundling File Naming (Hash, ContentHash, ChunkHash)In Webpack, how files are named during bundling is a crucial performance optimization strategy. Proper naming ensures that browsers can cache files correctly, avoiding unnecessary network requests and improving application loading speed. Here are three common bundling file naming techniques: Hash, ContentHash, and ChunkHash. HashHash is generated based on file content. When file content changes, its corresponding hash value also changes. In Webpack, you can use the [hash] placeholder to represent the hash value. output: &#123; filename: 'bundle.[hash].js', &#125; ContentHashContentHash is generated based on file content as well, but unlike Hash, it’s solely influenced by file content and remains unaffected by file name or path changes. In Webpack, you can use the [contenthash] placeholder to represent the ContentHash value. output: &#123; filename: 'bundle.[contenthash].js', &#125; ChunkHashChunkHash is generated based on module content. Different module contents result in different ChunkHash values. In Webpack, you can use the [chunkhash] placeholder to represent the ChunkHash value. output: &#123; filename: '[name].[chunkhash].js', &#125; Performance Optimization - Implementing Tree Shaking in WebpackJavaScript Tree Shaking: Tree Shaking in JavaScript originates from the rollup bundler, a build tool. It relies on the static syntax analysis of ES Modules (no code execution) to determine module dependencies. Webpack 2 introduced native support for ES2015 modules, enhancing tree shaking capabilities. Webpack 4 extended this ability and introduced the sideEffects property in package.json to indicate which files have no side effects, allowing webpack to safely remove unused code. In Webpack 5, partial CommonJS tree shaking support was introduced. CommonJS Tree Shaking Implementing Tree Shaking in JavaScriptWebpack implements Tree Shaking through two methods: usedExports: Marking certain functions as used and optimizing them using Terser. sideEffects: Skipping entire modules&#x2F;files and checking if they have side effects. Tree Shaking for CSSTree Shaking for CSS involves using additional plugins. While PurifyCss was used previously, it’s no longer maintained. An alternative is PurgeCSS, a tool for removing unused CSS. Note: This translation includes placeholder strings like [hash], [contenthash], and [chunkhash] to represent dynamic values. Please replace these placeholders with appropriate values based on your specific use case.","link":"/2023/10/26/en/Webpack-optimization-1/"},{"title":"Webpack Performance Optimization-2","text":"Performance Optimization - JS-CSS Code Minification Terser is a toolset for JavaScript parsing, mangling, and compressing. In the early days, we used uglify-js to minify and uglify our JavaScript code. However, it is no longer maintained and does not support ES6+ syntax. Terser is a fork of uglify-es and retains most of its original APIs, compatible with uglify-es and uglify-js@3, etc. webpack-terser JavaScript Code MinificationWebpack provides the terser-webpack-plugin plugin for code optimization and minification. In production mode, TerserPlugin is used by default for code processing. const TerserPlugin = require('terser-webpack-plugin'); module.exports = &#123; // Configure other Webpack options... optimization: &#123; minimizer: [new TerserPlugin()], &#125;, &#125;; CSS Code MinificationApart from JavaScript code, CSS code can also be minified using Webpack. Use css-minimizer-webpack-plugin to compress CSS code. const CssMinimizerPlugin = require('css-minimizer-webpack-plugin'); module.exports = &#123; // Configure other Webpack options... optimization: &#123; minimizer: [ new CssMinimizerPlugin(), // You can continue adding other compression plugins... ], &#125;, &#125;; Tree Shaking Implementation in WebpackTree shaking is a term commonly used to describe the removal of dead code in JavaScript context. Tree Shaking in WebpackIn modern front-end development, optimizing code size is a crucial topic. Tree shaking is an optimization technique used to eliminate unused JavaScript modules in a project, reducing the size of the bundled files. Webpack provides built-in support, making it easy to implement tree shaking in projects. Enable ES Module SyntaxFirst, ensure your JavaScript code follows ES module syntax, as Webpack’s tree shaking feature only works with ES modules. Use import and export syntax to define modules in your project. // math.js export function square(x) &#123; return x * x; &#125; export function cube(x) &#123; return x * x * x; &#125; Webpack ConfigurationIn the Webpack configuration file, ensure the following settings to enable tree shaking: Set mode to &#39;production&#39;. Webpack will automatically enable related optimizations, including tree shaking. Implementing Tree Shaking for JavaScriptWebpack implements tree shaking using two different approaches: usedExports: Marks certain functions as used, and later optimizes them with Terser. sideEffects: Skips entire modules&#x2F;files and checks if the file has side effects. Using usedExports to Implement Tree ShakingSet the mode to production: module.exports = &#123; mode: 'production', // ...other configurations &#125;; Configure usedExports in the optimization section: const path = require('path'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist'), &#125;, mode: 'development', optimization: &#123; usedExports: true, &#125;, &#125;; Using sideEffects to Implement Tree ShakingSet the sideEffects field in package.json: Set it to false to inform Webpack that it can safely remove unused exports. If there are specific files you want to keep, set it as an array. &#123; \"name\": \"your-project\", \"sideEffects\": [\"./src/some-side-effectful-file.js\"] &#125; Webpack Side Effects Understanding Tree Shaking and sideEffectssideEffects and usedExports (more commonly considered tree shaking) are two different optimization techniques. sideEffects is more efficient as it allows skipping entire modules&#x2F;files and their entire subtree. usedExports depends on terser to detect side effects in statements. It’s a more complex JavaScript task and is not as straightforward as sideEffects. Also, it cannot skip subtrees&#x2F;dependencies because side effects need to be evaluated. While exported functions work as usual, higher-order functions (HOC) in the React framework can have issues in this scenario. CSS Tree Shaking ImplementationFor CSS tree shaking, additional plugins are required. In the past, PurifyCss plugin was used for CSS tree shaking, but it’s no longer maintained (last update was 4 years ago). A different library, PurgeCSS, can now be used for CSS tree shaking, helping remove unused CSS. File Compression in WebpackWhat is HTTP CompressionHTTP compression is a technique used between servers and clients to improve transmission speed and bandwidth utilization.The process of HTTP compression is as follows: Data is compressed on the server before being sent. (Can be done in Webpack) Compatible browsers inform the server about supported compression formats during requests. The server returns the corresponding compressed file to the browser, indicating it in the response headers. Popular Compression FormatsThere are several popular compression formats: compress: Method used by UNIX’s “compress” program (historical reasons, not recommended for most applications, use gzip or deflate instead). deflate: Compression based on the deflate algorithm (defined in RFC 1951) and encapsulated in zlib data format. gzip: GNU zip format (defined in RFC 1952), widely used compression algorithm. br: A new open-source compression algorithm designed specifically for HTTP content encoding. Webpack Configuration for File CompressionWebpack essentially performs the first step of HTTP compression. You can use the CompressionPlugin for this purpose. Step 1: Install CompressionPlugin: npm install compression-webpack-plugin -D Step 2: Use CompressionPlugin in your Webpack configuration: module.exports = &#123; plugins: [ new CompressionPlugin(&#123; test: /\\.js(\\?.*)?$/i, &#125;), ], &#125;;","link":"/2023/10/27/en/Webpack-optimization-2/"},{"title":"How to Use `sideEffects` in Webpack","text":"Webpack v4 introduced a new feature called sideEffects, which allows you to declare in your package.json whether a package&#x2F;module contains side effects or not. This declaration provides more optimization space for tree-shaking. In the conventional understanding of side effects, if we are certain that the modules within our package have no side effects, we can mark the package in npm with &quot;sideEffects&quot;: false in package.json. This allows us to offer a better bundling experience for consumers. The principle behind this is that Webpack can transform imports like import &#123;a&#125; from xx into import &#123;a&#125; from &#39;xx/a&#39; for packages marked as side-effects-free, automatically trimming unnecessary imports, similar to babel-plugin-import. Tree Shaking and Side EffectsTree shaking, first introduced and implemented by Rollup in the frontend community, has been a topic of discussion in various articles about optimizing bundling. Principles of Tree ShakingES6 module imports are statically analyzable, meaning the compiler can accurately determine what code is loaded during compilation. The program flow is analyzed to identify unused or unreferenced variables, which are then removed from the code. The principle sounds perfect, so why do we sometimes find that unnecessary code in our projects isn’t eliminated? The reason is side effects. Side EffectsFor those familiar with functional programming, the term “side effect” is not unfamiliar. It can be broadly understood as any action of a function that might or might not affect variables outside its scope. For example, consider this function: function go(url) &#123; window.location.href = url; &#125; This function modifies the global variable location and even triggers a browser redirect, making it a function with side effects. // components.js export class Person &#123; constructor(&#123; name &#125;) &#123; this.className = 'Person'; this.name = name; &#125; getName() &#123; return this.name; &#125; &#125; export class Apple &#123; constructor(&#123; model &#125;) &#123; this.className = 'Apple'; this.model = model; &#125; getModel() &#123; return this.model; &#125; &#125; // main.js import &#123; Apple &#125; from './components'; const appleModel = new Apple(&#123; model: 'IphoneX' &#125;).getModel(); console.log(appleModel); In this code, the Person class is clearly unused. However, why can other tools like Rollup successfully eliminate unused code, while Webpack cannot? The answer lies in Babel compilation + Webpack bundling. I’ll provide a link here that explains in detail how Babel compilation + Webpack bundling might prevent effective code elimination: Your Tree-Shaking Isn’t Working. If you don’t want to read the article, here’s a brief explanation: Babel compilation wraps the Person class in an IIFE (Immediately Invoked Function Expression) and returns a constructor, introducing a side effect. There’s an issue related to this: Class declarations inside IIFEs are considered side effects. When I declare a class inside an IIFE and don’t use the class, UglifyJS doesn’t remove it because it’s considered a side effect. var V6Engine = (function () &#123; function V6Engine() &#123; &#125; V6Engine.prototype.toString = function () &#123; return 'V6'; &#125;; return V6Engine; &#125;()); During compilation, you might receive this warning: WARN: Side effects in initialization of unused variable V6Engine [./dist/car.bundle.js:74,4]. The reason is that UglifyJS doesn’t perform complete program flow analysis. It doesn’t remove code because you noticed a side effect. If you want a more sophisticated tree shaking, go check out Rollup! Summarizing some key points from the issue: If a function’s parameter is a reference type, any operations on its properties could potentially have side effects. This is because it’s a reference type, and any modification to its properties affects data outside the function. Additionally, accessing or modifying its properties triggers getter or setter, which are opaque and may have side effects. UglifyJS lacks complete program flow analysis. It can simple judge whether a variable is later referenced or modified but cannot determine the complete modification process of a variable. It doesn’t know if it points to an external variable, so many potentially side-effect-causing code cannot be removed. Rollup has the ability to perform program flow analysis, making it better at determining whether code truly has side effects. However, these issues were prevalent in older versions. The current Webpack tree shaking has undergone many optimizations and can perform sufficient program flow analysis for tree shaking. The purpose of Webpack’s tree shaking is to mark unused exported members as unused and not export them in the modules where they are re-exported. It sounds complicated, but looking at the code makes it clearer: // a.js export function a() &#123;&#125; // b.js export function b()&#123;&#125; // package/index.js import a from './a' import b from './b' export &#123; a, b &#125; // app.js import &#123;a&#125; from 'package' console.log(a) When using app.js as the entry point, the code after tree shaking becomes: // a.js export function a() &#123;&#125; // b.js is no longer exported: function b()&#123;&#125; function b() &#123;&#125; // package/index.js does not export module b anymore import a from './a' import './b' export &#123; a &#125; // app.js import &#123;a&#125; from 'package' console.log(a) After combining Webpack’s scope hoisting and uglify, all traces of module b will be completely eliminated. But what if module b contains some side effects, such as a simple log: // b.js export function b(v) &#123; return v &#125; console.log(b(1)) After webpack, the content of module `b` becomes: // b.js console.log(function (v)&#123;return v&#125;(1)) Although the export of module b is ignored, the code with side effects is retained. Due to various strange operations introduced by the transformer after compilation, which may cause side effects, we often find that even with tree shaking, our bundle size doesn’t significantly decrease. Usually, we expect that if module b is not being used, none of its code should be included. This is where the role of sideEffects becomes apparent: if the imported package&#x2F;module is marked as &quot;sideEffects: false&quot;, regardless of whether it truly has side effects, as long as it’s not being referenced, the entire module&#x2F;package will be completely removed. Taking mobx-react-devtools as an example, we often use it like this: import DevTools from 'mobx-react-devtools'; class MyApp extends React.Component &#123; render() &#123; return ( &lt;div> ... &#123; process.env.NODE_ENV === 'production' ? null : &lt;DevTools /> &#125; &lt;/div> ); &#125; &#125; This is a common scenario of importing modules on demand. However, without the sideEffects: false configuration, even if NODE_ENV is set to production, the bundled code will still include the mobx-react-devtools package. Although we haven’t used any of its exported members, mobx-react-devtools will still be imported because it “might” have side effects. But when we add sideEffects: false, tree shaking can safely remove it entirely from the bundle. Use Cases of sideEffectsAs mentioned earlier, it’s often difficult to guarantee whether packages&#x2F;modules published on npm contain side effects (it could be the code’s fault or the transformer’s fault). However, we can usually ensure whether a package&#x2F;module will affect objects outside of it, such as modifying properties on the window object or overwriting native object methods. If we can guarantee this, we can determine whether a package can have &quot;sideEffects: false&quot;. Whether it truly has side effects is not that important for Webpack; it’s acceptable as long as it’s marked. This explains why packages with inherent side effects, like vue, can still have &quot;sideEffects: false&quot; applied. So, in Webpack, &quot;sideEffects: false&quot; doesn’t mean that the module truly has no side effects. It’s just a way to tell Webpack during tree shaking: “I designed this package with the expectation that it has no side effects, even if it ends up having side effects after being bundled.”","link":"/2023/10/27/en/Webpack-optimization-3/"},{"title":"pack-tool-preview","text":"I tried migrating a real project from Vite to Rspack. The build time reduced from 125 seconds to 17 seconds, and the page refresh speed during development increased by 64%. However, the HMR (Hot Module Replacement) in Rspack is much slower compared to Vite. If you frequently trigger HMR during development and refresh the page less often, Vite still offers a better development experience. For complex projects where refreshing the page is more common, Rspack provides a better development experience. There are so many frontend build tools out there: RollDown, Rollup, Rspack, Vite… Just a sneak peek; stay tuned for the detailed comparison.","link":"/2023/10/27/en/pack-tool-preview/"},{"title":"Webpack Custom Loader/Plugin","text":"IntroductionA loader is a node module exported as a function. This function is called when transforming resources in the loader. The given function will utilize the Loader API and can be accessed through the this context. Here is an official link on loader usage and examples, including local development and testing of custom loaders. Simple Usage of Webpack LoaderWhen a loader is used in a resource, it can only take one parameter - a string containing the content of the resource file. Synchronous loaders can return a single value representing the transformed module. Loaders can return one or two values. The first value is a string or buffer containing JavaScript code. The optional second value is a SourceMap, which is a JavaScript object. Here’s a simple example of using a loader. It matches all JavaScript files and processes them using loader.js: // webpack.config.js const path = require('path'); module.exports = &#123; //... module: &#123; rules: [ &#123; test: /\\.js$/, use: [ &#123; loader: path.resolve('path/to/loader.js'), options: &#123; /* ... */ &#125;, &#125;, ], &#125;, ], &#125;, &#125;; From the above, we can understand how loaders are used. But this only scratches the surface. What does a specific loader look like? For example, a simple loader could be like this: module.exports = function (content) &#123; // content is the source content string passed in return content &#125; A loader is just a node module exposing a function that can only receive one parameter: a string containing the content of the resource file. The function’s return value is the processed content. Creating a Custom Webpack LoaderGuidelines for Using Custom LoadersWhen writing loaders, you should follow these guidelines. They are listed in order of importance, and some apply only to specific scenarios. Please read the detailed sections below for more information. Keep it simple. Use chaining. Output should be modular. Ensure it’s stateless. Use loader utilities. Record loader dependencies. Resolve module dependencies. Extract common code. Avoid absolute paths. Use peer dependencies. Step 1: Create Project Directory and FilesFirst, create the following files in a folder within your webpack project directory: src/loader/custom-loader.js: The source file for your custom loader. src/index.js: JavaScript entry file for testing the custom loader. Step 2: Write the Custom LoaderIn the custom-loader.js file, write your custom loader code. This loader adds a comment at the top of each loaded JavaScript file. // src/loader/custom-loader.js module.exports = function(source) &#123; // Add a custom comment at the top of the source code const updatedSource = `/** Custom Comment added by Custom Loader */\\n$&#123;source&#125;`; return updatedSource; &#125;; Step 3: Configure WebpackCreate a Webpack configuration file webpack.config.js in the project root directory. Use the custom loader you just created in the configuration file. // webpack.config.js const path = require('path'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist'), &#125;, module: &#123; rules: [ &#123; test: /\\.js$/, use: ['custom-loader'], // Use the custom loader to process .js files exclude: /node_modules/, &#125;, ], &#125;, &#125;; This configuration achieves a simple functionality. Now let’s discuss how to test the local loader. There are two ways to do this: one is through Npm link for testing, a convenient method where you can create a symbolic link for local testing. Here is a link to npm-link. Another way is to configure the path directly in the project: Single Loader Configuration// webpack.config.js &#123; test: /\\.js$/ use: [ &#123; loader: path.resolve('path/to/custom-loader.js'), options: &#123;/* ... */&#125; &#125; ] &#125; Multiple Loader ConfigurationYou can also configure it using an array: // webpack.config.js resolveLoader: &#123; // Look for loaders first in the node_modules directory; if not found, search in the loaders directory modules: [ 'node_modules', path.resolve(__dirname, 'custom-loader') ] &#125; Step 4: Test the Custom LoaderIn the index.js file, write some JavaScript code, for example: // src/index.js console.log('Hello, Webpack Loader!'); Step 5: Run Webpack BuildRun the following command to build your project: npx webpack --config webpack.config.js After the build is complete, you will find the generated bundle.js file in the dist folder. In this file, you can see JavaScript code with a custom comment added at the top. ## Simple Usage of Webpack Plugin Plugins provide complete control over the webpack engine for third-party developers. By introducing custom behaviors into the webpack build process through stage-based build callbacks, developers can customize webpack&#39;s behavior. Here&#39;s the simplest example: &#96;&#96;&#96;javascript &#x2F;&#x2F; webpack.config.js const HtmlWebpackPlugin &#x3D; require(&#39;html-webpack-plugin&#39;); module.exports &#x3D; &#123; entry: &#39;.&#x2F;src&#x2F;index.js&#39;, output: &#123; filename: &#39;bundle.js&#39;, path: __dirname + &#39;&#x2F;dist&#39;, &#125;, plugins: [ new HtmlWebpackPlugin(&#123; template: &#39;.&#x2F;src&#x2F;index.html&#39;, &#x2F;&#x2F; Specify the HTML template file filename: &#39;index.html&#39;, &#x2F;&#x2F; Generated HTML file name &#125;), &#x2F;&#x2F; You can add more plugins here ], &#125;; In this example, the HtmlWebpackPlugin is used. It generates a new HTML file based on the specified HTML template and automatically adds the bundled JavaScript file to the generated HTML file. A basic webpack plugin consists of the following components: A JavaScript named function or JavaScript class. Define an apply method on the plugin function’s prototype. The apply method is called when webpack loads the plugin and is passed the compiler object. Specify an event hook bound to webpack itself. Process specific data from webpack’s internal instances. Call the callback provided by webpack after the functionality is completed. A plugin structure looks like this: class HelloWorldPlugin &#123; apply(compiler) &#123; compiler.hooks.done.tap( 'Hello World Plugin', ( stats /* After binding the done hook, stats is passed as a parameter. */ ) => &#123; console.log('Hello World!'); &#125; ); &#125; &#125; module.exports = HelloWorldPlugin; Compiler and CompilationThe two most important resources in plugin development are the compiler and compilation objects. Plugin development revolves around hooks on these objects. The compiler object is essentially bound to the entire webpack environment. It contains all the environment configurations, including options, loaders, and plugins. When webpack starts, this object is instantiated and it is globally unique. The parameters passed into the apply method are properties of this object. The compilation object is created each time resources are built. It represents the current module resources, compiled generated resources, changed files, and tracked dependency status. It also provides many hooks. Creating a Custom Webpack PluginStep 1: Create Project Directory and FilesFirst, create the following file in a folder within your webpack project directory: src/plugins/CustomPlugin.js: Source file for your custom plugin. Step 2: Write the Custom PluginIn the CustomPlugin.js file, write a plugin that outputs a message when the webpack build process is completed. // src/plugins/CustomPlugin.js class CustomPlugin &#123; apply(compiler) &#123; compiler.hooks.done.tap('CustomPlugin', () => &#123; console.log('CustomPlugin: Webpack build process is done!'); &#125;); &#125; &#125; module.exports = CustomPlugin; Step 3: Configure WebpackIn the configuration file, use the custom plugin you just created. // webpack.config.js const CustomPlugin = require('./src/plugins/CustomPlugin'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: __dirname + '/dist', &#125;, plugins: [ new CustomPlugin(), // You can add more plugins here ], &#125;; Step 4: Run Webpack BuildNow, run the webpack build: npx webpack --config webpack.config.js","link":"/2023/10/29/en/webpack-plugin-design/"},{"title":"Understanding Ajax and Cross-Origin Requests Easily","text":"IntroductionWhen learning to write web pages, you usually start with HTML and CSS, which are responsible for creating and beautifying the layout. Once you have a solid foundation, you start learning JavaScript to create interactive effects. In addition to user and browser interactions, don’t forget about the interaction between the client and server, which means you must learn how to use JavaScript to retrieve data from the backend server. Otherwise, your web page data will be static. The main target audience of this article is beginners in web front-end development. I hope that after reading this article, readers who do not understand how to exchange data with the server or how to connect to APIs can have a better understanding of how to connect to the backend. Let’s start with an exampleBefore we begin, let’s consider a question: Why does the front-end need to exchange data with the backend? Actually, this depends on the type of web page you are creating. If you are creating an official website, the entire website is likely to be static, and only HTML and CSS are required, without the need to retrieve data from the backend server. Let’s assume that today we want to create a web page that can browse the current Twitch live stream list, as shown below. If this web page does not retrieve data from the backend, it means that the content of the web page is fixed and will remain the same no matter when it is viewed. However, this is not correct because the goal of this web page is to display “channels that are currently live,” so the content will change accordingly. Since the content will change, we must continuously update the data, retrieve data from the server, and then display it after processing it on the front-end. After confirming the need to retrieve data, we can ask ourselves two questions: Who do we retrieve data from? How do we retrieve data? The answer to the first question is obviously Twitch because Twitch has the data we need! As for the second question, we must use the Twitch API. APIWhat is an API? You may have heard this term many times, but still don’t know what it means. Let’s start with its full name, which is “Application Programming Interface.” You may wonder what this is and why I can’t understand it in both Chinese and English. But actually, the most important thing in these few words is the word “interface.” What is an interface? An interface is used for connection. I’ll give you an example. Isn’t there a USB slot on your computer? As long as you see USB flash drives on the market, you can buy them and plug them into the USB slot, and your computer can read them. Have you ever wondered why? Although they are made by different manufacturers, they can all be read and plugged into the USB slot. This is because there is a standard called the USB interface. After this standard was established, as long as all manufacturers develop according to this standard, they can ensure that they can connect to the computer and USB flash drives. API is the same, but it becomes a connection between programs. For example, if I need to read a file in my program, how do I read it? Reading files is a function provided by the operating system, so I can connect to the “read file API” and use this function in my program. I’ll give you a few more examples. Suppose I want to allow my web page to log in with Facebook. What should I do? I need to connect to the “Facebook API,” which is a set of standards provided by Facebook to everyone who wants to access Facebook services. Any developer who wants to access Facebook services can follow these standards to obtain the data they want. This thing is called an API. Or maybe you are a developer of a hotel management system today, and your company has developed an ERP for hotels, which can manage the booking status of hotels and so on, and can know which rooms are empty now. If you only use this data yourself, it would be a pity. Therefore, the company decided to provide this data to large booking websites, which can display the room status of this hotel in real-time on those websites. Therefore, data exchange is necessary, and you need to provide a “query room status API” to other websites so that they can connect to it and obtain this information. By now, you should have some sense of what an API is. Let me give you a few more examples: I want to retrieve photos from Flickr, so I need to connect to the Flickr API. Google wants to allow other apps to log in and authenticate with Google, so Google needs to provide the “Google login API.” I want to retrieve the channels currently available on Twitch, so I need to connect to the Twitch API. API DocumentationNow that we know what an API is and that we need to connect to it, the next question is “how do we connect?” Earlier, we mentioned an example of file access. This is actually more like calling a function provided by the operating system or a programming language library. You can usually find more detailed information about these functions in the official documentation, such as reading files in Node.js: (Source: https://nodejs.org/api/fs.html#fs_fs_readdir_path_options_callback) Above, it is written which function you should call and what parameters you should pass in. API integration is the same. You must have documentation to know how to integrate, otherwise you cannot integrate at all because you don’t even know what parameters to pass. Let’s take a look at how the Twitch API documentation is written. It explains that you must have a Client ID, and the API Root URL is https://api.twitch.tv/kraken, etc. These are basic information related to the API. If you click on any API in the left column, you will see detailed information about each API: Here, it is written what the URL is, what parameters you should pass, etc. There are also reference examples below, which is a very complete API documentation. Usually, when writing web pages, we directly talk about APIs, but actually we are referring to Web APIs, which are APIs transmitted through the network. Are there non-Web APIs? Yes, like the file reading API we mentioned earlier, they are all executed locally on the computer without going through any network. But this doesn’t really matter, everyone is used to talking about APIs, as long as they can understand it. Now that we have the API documentation, we have all the information we need. Using the Twitch example above, as long as we can send a request to https://api.twitch.tv/kraken/games/top?client_id=xxx through JavaScript, Twitch will return the current list of the most popular games. We have narrowed down the scope of the problem step by step. At first, it was “how to get data from Twitch”, and now it is divided into: “how to use JavaScript to send a request”. AjaxTo send a request on the browser, you must use a technology called Ajax, which stands for “Asynchronous JavaScript and XML”, with the emphasis on the word “Asynchronous”. Before talking about what is asynchronous, let’s first mention what is synchronous. Almost all JavaScript you originally wrote is executed synchronously. This means that when it executes to a certain line, it will wait for this line to finish executing before executing the next line, ensuring the execution order. That is to say, the last line of the following code needs to wait for a long time to be executed: var count = 10000000; while(count--) &#123; // Do some time-consuming operations &#125; // Executed after a long time console.log('done') It looks reasonable. Isn’t the program executed line by line? But if it involves network operations, everyone can think about the following example: // Assuming there is a function called sendRequest to send a request var result = sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx'); // Executed after a long time console.log(result); When JavaScript executes sendRequest, because it is synchronous, it will wait for the response to come back before continuing to do anything. In other words, before the response comes back, the entire JavaScript engine will not execute anything! It’s scary, isn’t it? You click on anything related to JavaScript, and there is no response because JavaScript is still waiting for the response. Therefore, for operations that are expected to be very time-consuming and unstable, synchronous execution cannot be used, but asynchronous execution must be used. What does asynchronous mean? It means that after it is executed, it will not be taken care of, and it will continue to execute the next line without waiting for the result to come back: // Assuming there is a function called sendRequest to send a request var result = sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx'); // The above request is executed, and then it executes to this line, so result will not have anything // because the response has not returned yet console.log(result); Please note that “asynchronous functions cannot directly return results through return”. Why? Because, as in the example above, after sending a request, the next line will be executed, and at this time, there is no response yet. What should be returned? So what should we do? Let me give you a very common example! When I was eating in a food court in Singapore, there was a table number on each table. When you order, just tell the boss which table you are sitting at, and the boss will deliver it to you after the meal is ready. So I don’t need to stand at the door of the store and wait. I just continue to sit on my own things. Anyway, the boss will deliver it to me after the meal is ready. The concept of asynchronous is also like this. After I send a request (after I order), I don’t need to wait for the response to come back (I don’t need to wait for the boss to finish), I can continue to do my own thing. After the response comes back (after the meal is ready), it will help me deliver the result (the boss will deliver it by himself). In the ordering example, the boss can know where to send the data through the table number. What about in JavaScript? Through Function! And this function, we call it a Callback Function, a callback function. When the asynchronous operation is completed, this function can be called and the data can be brought in. // Assuming there is a function called sendRequest to send a request sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx', callMe); function callMe (response) &#123; console.log(response); &#125; // Or write it as an anonymous function sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx', function (response) &#123; console.log(response); &#125;); Now you know why network operations are asynchronous and what callback functions are. XMLHttpRequestJust mentioned the concepts of Ajax, asynchronous, and callback functions, but didn’t say how to send a request, just wrote a fake sendRequest function as a reference. To send a request, we need to use an object prepared by the browser called XMLHttpRequest. The sample code is as follows: var request = new XMLHttpRequest(); request.open('GET', `https://api.twitch.tv/kraken/games/top?client_id=xxx`, true); request.onload = function() &#123; if (request.status >= 200 &amp;&amp; request.status &lt; 400) &#123; // Success! console.log(request.responseText); &#125; &#125;; request.send(); The request.onload above actually specifies which function to use to handle the data when it comes back. With the above code, you have finally succeeded and can finally connect to the Twitch API and get data from there! It’s really gratifying. From now on, you will live a happy life with the skill of “connecting to the API”… Not really. Same Origin PolicyJust when you thought you were already familiar with connecting to APIs and wanted to try connecting to other APIs, you found that a problem occurred with just one line: XMLHttpRequest cannot load http:&#x2F;&#x2F;odata.tn.edu.tw&#x2F;ebookapi&#x2F;api&#x2F;getOdataJH&#x2F;?level&#x3D;all. No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource. Origin &#39;null&#39; is therefore not allowed access. Huh? Why is there this error? In fact, for security reasons, the browser has something called the Same-origin policy. This means that if the website you are currently on and the API website you want to call are “different sources”, the browser will still help you send the request, but it will block the response, preventing your JavaScript from receiving it and returning an error. What is a different source? Simply put, if the domain is different, it is a different source, or if one uses http and the other uses https, or if the port numbers are different, it is also a different source. So if you are using someone else’s API, in most cases it will be a different source. I want to emphasize here that “your request is still sent”, and the browser “does receive the response”, but the key point is that “due to the same-origin policy, the browser does not pass the result back to your JavaScript”. If there is no browser, there is actually no such problem. You can send it to whoever you want and get the response no matter what. Okay, since we just said that different sources will be blocked, how did we successfully connect to the Twitch API? CORSAs we all know, it is very common to transfer data between different sources, just like we connect to the Twitch API. How can we be under the same domain as the Twitch API? Therefore, the same-origin policy does regulate that non-same-origin requests will be blocked, but at the same time, there is another regulation that says: “If you want to transfer data between different origins, what should you do?” This regulation is called CORS. CORS, short for Cross-Origin Resource Sharing, is a cross-origin resource sharing protocol. This protocol tells you that if you want to open cross-origin HTTP requests, the server must add Access-Control-Allow-Origin to the response header. You should be familiar with this field. If you feel unfamiliar, you can go back and look at the error message just now, which actually mentioned this header. After the browser receives the response, it will first check the content of Access-Control-Allow-Origin. If it contains the origin of the request that is currently being initiated, it will allow it to pass and allow the program to receive the response smoothly. If you carefully check the request we sent to Twitch in the beginning, you will find that the header of the response is roughly like this: Content-Type: application&#x2F;json Content-Length: 71 Connection: keep-alive Server: nginx Access-Control-Allow-Origin: * Cache-Control: no-cache, no-store, must-revalidate, private Expires: 0 Pragma: no-cache Twitch-Trace-Id: e316ddcf2fa38a659fa95af9012c9358 X-Ctxlog-Logid: 1-5920052c-446a91950e3abed21a360bd5 Timing-Allow-Origin: https:&#x2F;&#x2F;www.twitch.tv The key point is this line: Access-Control-Allow-Origin: *, where the asterisk represents a wildcard character, meaning that any origin is accepted. Therefore, when the browser receives this response, it compares the current origin with the * rule, passes the verification, and allows us to accept the response of the cross-origin request. In addition to this header, there are actually others that can be used, such as Access-Control-Allow-Headers and Access-Control-Allow-Methods, which can define which request headers and methods are accepted. To sum up, if you want to initiate a cross-origin HTTP request and receive a response smoothly, you need to ensure that the server side has added Access-Control-Allow-Origin, otherwise the response will be blocked by the browser and an error message will be displayed. Preflight RequestDo you still remember Twitch’s API documentation? It requires a client-id parameter, and the document says that you can pass it in the GET parameter or in the header. Let’s try passing it in the header! Open Devtool, and you will see a magical phenomenon: Huh? I clearly only sent one request, why did it become two? And the method of the first one is actually OPTIONS. Why did adding one header result in an extra request? In fact, this is also related to CORS mentioned above. CORS divides requests into two types, one is a simple request. What is a simple request? There is actually a long definition, which I think you can read when you need it. But in short, if you don’t add any custom headers, and it’s a GET request, it’s definitely a simple request (isn’t this simple enough?). On the contrary, if you add some custom headers, such as the Client-ID we just added, this request is definitely not a simple request. (Definition reference: MDN: Simple Request) From the above classification, we know that the request we just initiated is not a simple request because it has a custom header. So why is there an extra request? This request is called a Preflight Request, which is used to confirm whether subsequent requests can be sent because non-simple requests may contain some user data. If this Preflight Request fails, the real request will not be sent, which is the purpose of the Preflight Request. Let me give you an example, and you will know why this Preflight Request is needed. Assuming that a server provides an API URL called: https://example.com/data/16, you can get the data with id 16 by sending a GET request to it, and you can delete this data by sending a DELETE request to it. If there is no Preflight Request mechanism, I can send a DELETE request to this API on any web page of any domain. As I emphasized earlier, the browser’s CORS mechanism will still help you send the request, but only the response will be blocked by the browser. Therefore, even though there is no response, the server did receive this request, so it will delete this data. If there is a Preflight Request, when receiving the result of the request, it will know that this API does not provide CORS, so the real DELETE request will not be sent, and it will end here. The purpose of the Preflight Request is to use an OPTIONS request to confirm whether the subsequent request can be sent. JSONPFinally, let’s talk about JSONP, which is another method for cross-origin requests besides CORS, called JSON with Padding. Do you remember the same-origin policy mentioned at the beginning? If you think about it carefully, you will find that some things are not restricted by the same-origin policy, such as the &lt;script&gt; tag. Don’t we often refer to third-party packages such as CDN or Google Analytics on web pages? The URLs are all from other domains, but they can be loaded normally. JSONP uses this feature of &lt;script&gt; to achieve cross-origin requests. Imagine you have an HTML like this: &lt;script> var response = &#123; data: 'test' &#125;; &lt;/script> &lt;script> console.log(response); &lt;/script> It’s a very easy-to-understand piece of code, so I won’t explain it much. What if you replace the above code with a URL? &lt;script src=\"https://another-origin.com/api/games\">&lt;/script> &lt;script> console.log(response); &lt;/script> If the content returned by https://another-origin.com/api/games is the same as before: var response = &#123; data: 'test' &#125;; Then can’t I get the data in the same way? And these data are still controlled by the server, so the server can give me any data. But using global variables like this is not very good. We can use the concept of Callback Function just mentioned and change it to this: &lt;script> receiveData(&#123; data: 'test' &#125;); &lt;/script> &lt;script> function receiveData (response) &#123; console.log(response); &#125; &lt;/script> So what is JSONP? JSONP actually uses the above format to put data in &lt;script&gt; and bring the data back through the specified function. If you think of the first &lt;script&gt; as the server’s return value, you will understand. In practice, when operating JSONP, the server usually provides a callback parameter for the client to bring over. The Twitch API provides a JSONP version, and we can directly look at the example. URL: https://api.twitch.tv/kraken/games/top?client_id=xxx&amp;callback=aaa&amp;limit=1 aaa(&#123;\"_total\":1069,\"_links\":&#123;\"self\":\"https://api.twitch.tv/kraken/games/top?limit=1\",\"next\":\"https://api.twitch.tv/kraken/games/top?limit=1\\u0026offset=1\"&#125;,\"top\":[&#123;\"game\":&#123;\"name\":\"Dota 2\",\"popularity\":63361,\"_id\":29595,\"giantbomb_id\":32887,\"box\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-272x380.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-136x190.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-52x72.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"logo\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-240x144.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-120x72.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-60x36.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"_links\":&#123;&#125;,\"localized_name\":\"Dota 2\",\"locale\":\"zh-tw\"&#125;,\"viewers\":65243,\"channels\":373&#125;]&#125;) URL: https://api.twitch.tv/kraken/games/top?client_id=xxx&amp;callback=receiveData&amp;limit=1 receiveData(&#123;\"_total\":1067,\"_links\":&#123;\"self\":\"https://api.twitch.tv/kraken/games/top?limit=1\",\"next\":\"https://api.twitch.tv/kraken/games/top?limit=1\\u0026offset=1\"&#125;,\"top\":[&#123;\"game\":&#123;\"name\":\"Dota 2\",\"popularity\":63361,\"_id\":29595,\"giantbomb_id\":32887,\"box\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-272x380.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-136x190.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-52x72.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"logo\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-240x144.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-120x72.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-60x36.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"_links\":&#123;&#125;,\"localized_name\":\"Dota 2\",\"locale\":\"zh-tw\"&#125;,\"viewers\":65622,\"channels\":376&#125;]&#125;) Have you noticed? It passes the callback parameter you brought over as the function name and passes the entire JavaScript object to the Function, so you can get the data inside the Function. Combined, it would look like this: &lt;script src=\"https://api.twitch.tv/kraken/games/top?client_id=xxx&amp;callback=receiveData&amp;limit=1\">&lt;/script> &lt;script> function receiveData (response) &#123; console.log(response); &#125; &lt;/script> Using JSONP, you can also access cross-origin data. However, the disadvantage of JSONP is that the parameters you need to pass can only be passed through the URL in a GET request, and cannot be passed through a POST request. If CORS can be used, it should be prioritized over JSONP. SummaryThe content of this article starts with the process of fetching data and tells you step by step where to fetch it and how to fetch it. If you want to fetch data using an API, what is an API? How to call Web API in JavaScript? How to access cross-origin data? Generally speaking, I have mentioned everything related to fetching data with the front-end, but there is a regret that I did not mention the Fetch API, which is a newer standard used to fetch data. The introduction on MDN is: The Fetch API provides an interface for fetching resources (including across the network). It will seem familiar to anyone who has used XMLHttpRequest, but the new API provides a more powerful and flexible feature set. Interested readers can check it out for themselves. I hope that after reading this article, you will have a better understanding of how to connect to the back-end API and the difficulties you may encounter when connecting.","link":"/2017/08/27/en/ajax-and-cors/"}],"tags":[{"name":"http","slug":"http","link":"/en/tags/http/"},{"name":"Webpack","slug":"Webpack","link":"/en/tags/Webpack/"},{"name":"Ajax","slug":"Ajax","link":"/en/tags/Ajax/"},{"name":"JavaScript","slug":"JavaScript","link":"/en/tags/JavaScript/"},{"name":"Front-end","slug":"Front-end","link":"/en/tags/Front-end/"},{"name":"Build","slug":"Build","link":"/en/tags/Build/"}],"categories":[{"name":"http","slug":"http","link":"/en/categories/http/"},{"name":"Webpack","slug":"Webpack","link":"/en/categories/Webpack/"},{"name":"Front-end","slug":"Front-end","link":"/en/categories/Front-end/"},{"name":"Build","slug":"Build","link":"/en/categories/Build/"}]}