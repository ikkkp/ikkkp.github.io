{"pages":[{"title":"About Me","text":"Writing: A Soliloquy of the Soul “Writing is a soliloquy of the soul, a flow of the spirit.” - Wang Xiaobo I am ikkkp. In fact, the idea of creating my own personal website and sharing things I love on it has been in my mind for quite some time. The reason I write might not be very complicated. Words are my bridge to the world, a tool with which I think, feel, and touch life. Writing, for me, is a way to find companionship in solitude, a beacon of direction in moments of confusion. Words annotate life, and writing reveals the inner self. In this noisy world, writing has found me a sanctuary, a moment of tranquility. Writing allows me to think more clearly, to understand myself more profoundly. Every time I transform my thoughts into words, it’s like giving my soul a baptism, a process that helps me comprehend the depths of my inner world. Writing is also my way of connecting with others. Through words, I can convey my thoughts, share my experiences, and build profound emotional bonds with others. In the ocean of words, we can sail without constraints, exploring endless possibilities.","link":"/en/abouts/index.html"}],"posts":[{"title":"301/302 Redirection","text":"Introduction When configuring redirects on a website, especially in the following scenarios, issues can arise: Redirecting from HTTP to HTTPS: Suppose you’ve set up an SSL certificate to upgrade your website from HTTP to HTTPS. If problems occur during this process, rendering the site inaccessible, you might consider reverting to the HTTP version. However, the challenge arises once a permanent 301 redirection is in place. Even if you remove the redirection on the server, browsers retain this information. Consequently, users’ browsers continue to enforce the HTTPS redirection, preventing them from accessing the HTTP version. Changing the Website Domain: When migrating a website from one domain (such as old-domain.com) to another (such as new-domain.com), a permanent 301 redirection is often employed. This informs search engines and browsers that the site has permanently moved to a new domain. However, if complications arise during this process, you may wish to undo the redirection, allowing users to access the old domain again. Unfortunately, due to browser hard caching of 301 redirections, users become permanently redirected to the new domain, unable to revisit the old one. To avoid such situations, it is advisable to use a temporary 302 redirection initially, ensuring everything functions correctly. Unlike a 301 redirection, a 302 redirection is not permanently cached by browsers. This means that if necessary, you can revert the redirection without users being permanently locked into the new URL. This approach eliminates the need for users to manually clear their browser caches, enhancing the overall user experience. 301 Redirection: Indicates that a resource (page) has permanently moved to a new location. The client/browser should not attempt to request the original location but use the new location from now on. 302 Redirection: Indicates that the resource is temporarily located elsewhere, and the client/browser should continue requesting the original URL. A 301 redirection is permanent, meaning that even if removed from the server, browsers will perpetually redirect resources to the new domain or HTTPS due to hard caching. On the other hand, a 302 redirection is not hard-cached by browsers. If you remove the redirection from your server (website), you can still access the old version. Clearing 301/302 redirection cache typically involves clearing browser cache or the operating system’s DNS cache. Here’s how to do it on different platforms: Clearing Browser Cache (Applicable to Windows, macOS, Linux) Google Chrome: Open the Chrome browser. Click the three vertical dots in the upper right corner and select “More tools.” Choose “Clear browsing data.” In the popup window, select the “Advanced” tab. Set the time range to “All time.” Check the “Cached images and files” option. Click the “Clear data” button. Mozilla Firefox: Open the Firefox browser. Click the three horizontal lines in the upper right corner and select “Privacy &amp; Security.” In the “Cookies and Site Data” section, click “Clear Data.” Ensure the “Cache” option is checked. Click “Clear.” Microsoft Edge: Open the Edge browser. Click the three horizontal dots in the upper right corner and select “Settings.” Scroll down and click “View advanced settings.” In the “Privacy and services” section, click “Clear browsing data.” Check the “Cached images and files” option. Click the “Clear” button. Clearing Operating System’s DNS Cache (Applicable to Windows, macOS) Windows: Open Command Prompt (search for “cmd” in the Start menu and open it). Enter the following command and press Enter:ipconfig &#x2F;flushdns macOS: Open Terminal (find it in Applications &gt; Utilities folder). Enter the following command and press Enter:sudo dscacheutil -flushcache Then enter your administrator password and press Enter again. Please note that clearing browser cache might lead to loss of login sessions on websites. Ensure you have backed up essential information in case you need to log in again.","link":"/2023/10/28/en/301-302-Redirection/"},{"title":"Webpack Performance Optimization-1","text":"Introduction Let’s talk about why optimization is necessary. If your project is small and builds quickly, you might not need to worry too much about performance optimization. However, as your project grows with more pages, features, and business logic, the build time of webpack, the underlying build tool, also increases. At this point, optimizing performance becomes crucial. Webpack offers various avenues for performance optimization, which can be broadly categorized into two areas: Optimization One: Optimizing the built result for production, focusing on performance during deployment (e.g., code splitting, reducing bundle size, using CDN servers, etc.). Optimization Two: Optimizing build speed for development or production build, enhancing the speed of the build process (e.g., using exclusion, cache loaders, etc.). The performance during production directly affects user experience, whereas build time is closely related to developers’ daily workflow. If the local development server or production build takes too long, it significantly hampers productivity. Performance Optimization - Code Splitting Code splitting is a critical feature in webpack: Its primary purpose is to separate code into different bundles, which can be loaded on demand or in parallel. By default, all JavaScript code (business logic, third-party dependencies, and modules not immediately used) is loaded on the initial page load, impacting the loading speed. Code splitting allows creating smaller bundles and controlling resource loading priorities, thereby enhancing code loading performance. Webpack provides three common approaches to code splitting: Entry Points: Manually splitting code using entry configuration Preventing Duplication: Avoiding duplicate code using Entry Dependencies or SplitChunksPlugin Dynamic Imports: Splitting code using inline functions in modules Optimizing Entry Points - Entry Dependencies When a project has multiple entry points, there might be issues with duplicate dependencies. Some modules might be referenced in multiple entry points, causing redundancy in the final output, increasing the output file size. module.exports = &#123; entry: &#123; page1: &#123; import: './src/page1.js', dependOn: 'shared', &#125;, page2: &#123; import: './src/page2.js', dependOn: 'shared', &#125;, shared: './src/shared.js', &#125;, output: &#123; filename: '[name].bundle.js', path: __dirname + '/dist', &#125;, &#125;; Dynamic Imports Dynamic imports are a technique in webpack for lazy loading, allowing modules to load asynchronously at runtime instead of bundling all modules into a large initial file. This approach improves the initial loading speed and reduces the initial bundle size. const path = require('path'); module.exports = &#123; entry: &#123; main: './src/index.js', &#125;, output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist'), publicPath: '/', &#125;, module: &#123; rules: [ // Add your loader rules here ], &#125;, optimization: &#123; splitChunks: &#123; chunks: 'all', &#125;, &#125;, &#125;; In the above configuration, code splitting is achieved using optimization.splitChunks with the option chunks: 'all'. Then, dynamic imports can be used in the code like this: // Dynamically import modules where needed const loadModule = () => import('./Module'); loadModule().then(module => &#123; // Use the loaded module &#125;); Webpack will split the modules imported using import() into separate files. These files will be loaded asynchronously when needed during runtime. Custom Bundle Splitting - SplitChunks Bundle splitting is an optimization strategy that allows breaking down code into smaller pieces, enabling faster content display during loading. Webpack provides various strategies for bundle splitting, one of which involves using the SplitChunksPlugin plugin. This strategy is known as splitChunks. module.exports = &#123; // ...other configurations optimization: &#123; splitChunks: &#123; chunks: 'all', minSize: 30000, // Minimum size of the module before splitting minChunks: 1, // Minimum number of times a module should be duplicated before splitting maxAsyncRequests: 5, // Maximum number of parallel requests when loading modules on demand maxInitialRequests: 3, // Maximum number of parallel requests at an entry point automaticNameDelimiter: '~', name: true, cacheGroups: &#123; vendors: &#123; test: /[\\\\/]node_modules[\\\\/]/, priority: -10, reuseExistingChunk: true, &#125;, default: &#123; minChunks: 2, priority: -20, reuseExistingChunk: true, &#125;, &#125;, &#125;, &#125;, &#125;; For more information, refer to the webpack-split-chunks-plugin documentation. Performance Optimization - CDN CDN, or Content Delivery Network, refers to a network of interconnected servers strategically placed to deliver content to users efficiently. It ensures faster and more reliable delivery of resources such as music, images, videos, applications, and other files by utilizing servers closest to each user, providing high performance, scalability, and low-cost content delivery. In development, CDN is typically used in two ways: All static resources are bundled and stored on a CDN server, and users load resources exclusively through the CDN. Some third-party resources are hosted on CDN servers. Utilizing a Content Delivery Network (CDN) is a highly effective performance optimization strategy, especially within Webpack. CDN accelerates website loading speed, reduces server load, and enhances user experience. Here’s how you can configure and use CDN in Webpack: Using CDN for Third-Party Libraries Integrate third-party libraries used in your project (such as React, Vue, jQuery, etc.) through CDN links directly in the HTML file: &lt;script src=\"https://cdn.jsdelivr.net/npm/react@version/dist/react.min.js\">&lt;/script> &lt;script src=\"https://cdn.jsdelivr.net/npm/react-dom@version/dist/react-dom.min.js\">&lt;/script> Configuring Externals in Webpack In your Webpack configuration, utilize the externals field to inform Webpack about externally referenced modules that shouldn’t be bundled: module.exports = &#123; // ...other configurations externals: &#123; react: 'React', 'react-dom': 'ReactDOM', &#125;, &#125;; Then, include the CDN links in the HTML file using script tags: &lt;script src=\"https://cdn.jsdelivr.net/npm/react@version/dist/react.min.js\">&lt;/script> &lt;script src=\"https://cdn.jsdelivr.net/npm/react-dom@version/dist/react-dom.min.js\">&lt;/script> Configuring CDN’s publicPath In the Webpack output field, set the publicPath to specify the URL prefix for resource imports, typically set to the CDN’s address: module.exports = &#123; // ...other configurations output: &#123; // ...other output configurations publicPath: 'https://cdn.example.com/', &#125;, &#125;; This way, during Webpack build, all resource paths will be prefixed with the CDN’s address. Performance Optimization - Extracting CSS Files Extracting CSS files from JavaScript bundles is a common performance optimization strategy. This approach reduces the size of JavaScript files, speeds up page loading, and allows browsers to download CSS and JavaScript files in parallel, enhancing loading performance. In Webpack, you can achieve this using the mini-css-extract-plugin plugin. Webpack Configuration In your Webpack configuration file, include the mini-css-extract-plugin plugin and configure the module.rules to handle CSS files: const MiniCssExtractPlugin = require('mini-css-extract-plugin'); module.exports = &#123; // ...other configurations module: &#123; rules: [ &#123; test: /\\.css$/, use: [ MiniCssExtractPlugin.loader, 'css-loader', // Additional CSS loaders like postcss-loader and sass-loader can be added here ], &#125;, ], &#125;, plugins: [ new MiniCssExtractPlugin(&#123; filename: 'styles.css', // Filename for the extracted CSS file &#125;), ], &#125;; Including CSS Files In your JavaScript files or entry point file, import the CSS file: import './styles.css'; Alternatively, in the HTML file, use the link tag to include the extracted CSS file: &lt;link rel=\"stylesheet\" href=\"styles.css\"> Performance Optimization - Bundling File Naming (Hash, ContentHash, ChunkHash) In Webpack, how files are named during bundling is a crucial performance optimization strategy. Proper naming ensures that browsers can cache files correctly, avoiding unnecessary network requests and improving application loading speed. Here are three common bundling file naming techniques: Hash, ContentHash, and ChunkHash. Hash Hash is generated based on file content. When file content changes, its corresponding hash value also changes. In Webpack, you can use the [hash] placeholder to represent the hash value. output: &#123; filename: 'bundle.[hash].js', &#125; ContentHash ContentHash is generated based on file content as well, but unlike Hash, it’s solely influenced by file content and remains unaffected by file name or path changes. In Webpack, you can use the [contenthash] placeholder to represent the ContentHash value. output: &#123; filename: 'bundle.[contenthash].js', &#125; ChunkHash ChunkHash is generated based on module content. Different module contents result in different ChunkHash values. In Webpack, you can use the [chunkhash] placeholder to represent the ChunkHash value. output: &#123; filename: '[name].[chunkhash].js', &#125; Performance Optimization - Implementing Tree Shaking in Webpack JavaScript Tree Shaking: Tree Shaking in JavaScript originates from the rollup bundler, a build tool. It relies on the static syntax analysis of ES Modules (no code execution) to determine module dependencies. Webpack 2 introduced native support for ES2015 modules, enhancing tree shaking capabilities. Webpack 4 extended this ability and introduced the sideEffects property in package.json to indicate which files have no side effects, allowing webpack to safely remove unused code. In Webpack 5, partial CommonJS tree shaking support was introduced. CommonJS Tree Shaking Implementing Tree Shaking in JavaScript Webpack implements Tree Shaking through two methods: usedExports: Marking certain functions as used and optimizing them using Terser. sideEffects: Skipping entire modules/files and checking if they have side effects. Tree Shaking for CSS Tree Shaking for CSS involves using additional plugins. While PurifyCss was used previously, it’s no longer maintained. An alternative is PurgeCSS, a tool for removing unused CSS. Note: This translation includes placeholder strings like [hash], [contenthash], and [chunkhash] to represent dynamic values. Please replace these placeholders with appropriate values based on your specific use case.","link":"/2023/10/26/en/Webpack-optimization-1/"},{"title":"Webpack Performance Optimization-2","text":"Performance Optimization - JS-CSS Code Minification Terser is a toolset for JavaScript parsing, mangling, and compressing. In the early days, we used uglify-js to minify and uglify our JavaScript code. However, it is no longer maintained and does not support ES6+ syntax. Terser is a fork of uglify-es and retains most of its original APIs, compatible with uglify-es and uglify-js@3, etc. webpack-terser JavaScript Code Minification Webpack provides the terser-webpack-plugin plugin for code optimization and minification. In production mode, TerserPlugin is used by default for code processing. const TerserPlugin = require('terser-webpack-plugin'); module.exports = &#123; // Configure other Webpack options... optimization: &#123; minimizer: [new TerserPlugin()], &#125;, &#125;; CSS Code Minification Apart from JavaScript code, CSS code can also be minified using Webpack. Use css-minimizer-webpack-plugin to compress CSS code. const CssMinimizerPlugin = require('css-minimizer-webpack-plugin'); module.exports = &#123; // Configure other Webpack options... optimization: &#123; minimizer: [ new CssMinimizerPlugin(), // You can continue adding other compression plugins... ], &#125;, &#125;; Tree Shaking Implementation in Webpack Tree shaking is a term commonly used to describe the removal of dead code in JavaScript context. Tree Shaking in Webpack In modern front-end development, optimizing code size is a crucial topic. Tree shaking is an optimization technique used to eliminate unused JavaScript modules in a project, reducing the size of the bundled files. Webpack provides built-in support, making it easy to implement tree shaking in projects. Enable ES Module Syntax First, ensure your JavaScript code follows ES module syntax, as Webpack’s tree shaking feature only works with ES modules. Use import and export syntax to define modules in your project. // math.js export function square(x) &#123; return x * x; &#125; export function cube(x) &#123; return x * x * x; &#125; Webpack Configuration In the Webpack configuration file, ensure the following settings to enable tree shaking: Set mode to 'production'. Webpack will automatically enable related optimizations, including tree shaking. Implementing Tree Shaking for JavaScript Webpack implements tree shaking using two different approaches: usedExports: Marks certain functions as used, and later optimizes them with Terser. sideEffects: Skips entire modules/files and checks if the file has side effects. Using usedExports to Implement Tree Shaking Set the mode to production: module.exports = &#123; mode: 'production', // ...other configurations &#125;; Configure usedExports in the optimization section: const path = require('path'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist'), &#125;, mode: 'development', optimization: &#123; usedExports: true, &#125;, &#125;; Using sideEffects to Implement Tree Shaking Set the sideEffects field in package.json: Set it to false to inform Webpack that it can safely remove unused exports. If there are specific files you want to keep, set it as an array. &#123; \"name\": \"your-project\", \"sideEffects\": [\"./src/some-side-effectful-file.js\"] &#125; Webpack Side Effects Understanding Tree Shaking and sideEffects sideEffects and usedExports (more commonly considered tree shaking) are two different optimization techniques. sideEffects is more efficient as it allows skipping entire modules/files and their entire subtree. usedExports depends on terser to detect side effects in statements. It’s a more complex JavaScript task and is not as straightforward as sideEffects. Also, it cannot skip subtrees/dependencies because side effects need to be evaluated. While exported functions work as usual, higher-order functions (HOC) in the React framework can have issues in this scenario. CSS Tree Shaking Implementation For CSS tree shaking, additional plugins are required. In the past, PurifyCss plugin was used for CSS tree shaking, but it’s no longer maintained (last update was 4 years ago). A different library, PurgeCSS, can now be used for CSS tree shaking, helping remove unused CSS. File Compression in Webpack What is HTTP Compression HTTP compression is a technique used between servers and clients to improve transmission speed and bandwidth utilization. The process of HTTP compression is as follows: Data is compressed on the server before being sent. (Can be done in Webpack) Compatible browsers inform the server about supported compression formats during requests. The server returns the corresponding compressed file to the browser, indicating it in the response headers. Popular Compression Formats There are several popular compression formats: compress: Method used by UNIX’s “compress” program (historical reasons, not recommended for most applications, use gzip or deflate instead). deflate: Compression based on the deflate algorithm (defined in RFC 1951) and encapsulated in zlib data format. gzip: GNU zip format (defined in RFC 1952), widely used compression algorithm. br: A new open-source compression algorithm designed specifically for HTTP content encoding. Webpack Configuration for File Compression Webpack essentially performs the first step of HTTP compression. You can use the CompressionPlugin for this purpose. Step 1: Install CompressionPlugin: npm install compression-webpack-plugin -D Step 2: Use CompressionPlugin in your Webpack configuration: module.exports = &#123; plugins: [ new CompressionPlugin(&#123; test: /\\.js(\\?.*)?$/i, &#125;), ], &#125;;","link":"/2023/10/27/en/Webpack-optimization-2/"},{"title":"How to Use `sideEffects` in Webpack","text":"Webpack v4 introduced a new feature called sideEffects, which allows you to declare in your package.json whether a package/module contains side effects or not. This declaration provides more optimization space for tree-shaking. In the conventional understanding of side effects, if we are certain that the modules within our package have no side effects, we can mark the package in npm with &quot;sideEffects&quot;: false in package.json. This allows us to offer a better bundling experience for consumers. The principle behind this is that Webpack can transform imports like import &#123;a&#125; from xx into import &#123;a&#125; from 'xx/a' for packages marked as side-effects-free, automatically trimming unnecessary imports, similar to babel-plugin-import. Tree Shaking and Side Effects Tree shaking, first introduced and implemented by Rollup in the frontend community, has been a topic of discussion in various articles about optimizing bundling. Principles of Tree Shaking ES6 module imports are statically analyzable, meaning the compiler can accurately determine what code is loaded during compilation. The program flow is analyzed to identify unused or unreferenced variables, which are then removed from the code. The principle sounds perfect, so why do we sometimes find that unnecessary code in our projects isn’t eliminated? The reason is side effects. Side Effects For those familiar with functional programming, the term “side effect” is not unfamiliar. It can be broadly understood as any action of a function that might or might not affect variables outside its scope. For example, consider this function: function go(url) &#123; window.location.href = url; &#125; This function modifies the global variable location and even triggers a browser redirect, making it a function with side effects. // components.js export class Person &#123; constructor(&#123; name &#125;) &#123; this.className = 'Person'; this.name = name; &#125; getName() &#123; return this.name; &#125; &#125; export class Apple &#123; constructor(&#123; model &#125;) &#123; this.className = 'Apple'; this.model = model; &#125; getModel() &#123; return this.model; &#125; &#125; // main.js import &#123; Apple &#125; from './components'; const appleModel = new Apple(&#123; model: 'IphoneX' &#125;).getModel(); console.log(appleModel); In this code, the Person class is clearly unused. However, why can other tools like Rollup successfully eliminate unused code, while Webpack cannot? The answer lies in Babel compilation + Webpack bundling. I’ll provide a link here that explains in detail how Babel compilation + Webpack bundling might prevent effective code elimination: Your Tree-Shaking Isn’t Working. If you don’t want to read the article, here’s a brief explanation: Babel compilation wraps the Person class in an IIFE (Immediately Invoked Function Expression) and returns a constructor, introducing a side effect. There’s an issue related to this: Class declarations inside IIFEs are considered side effects. When I declare a class inside an IIFE and don’t use the class, UglifyJS doesn’t remove it because it’s considered a side effect. var V6Engine = (function () &#123; function V6Engine() &#123; &#125; V6Engine.prototype.toString = function () &#123; return 'V6'; &#125;; return V6Engine; &#125;()); During compilation, you might receive this warning: WARN: Side effects in initialization of unused variable V6Engine [./dist/car.bundle.js:74,4]. The reason is that UglifyJS doesn’t perform complete program flow analysis. It doesn’t remove code because you noticed a side effect. If you want a more sophisticated tree shaking, go check out Rollup! Summarizing some key points from the issue: If a function’s parameter is a reference type, any operations on its properties could potentially have side effects. This is because it’s a reference type, and any modification to its properties affects data outside the function. Additionally, accessing or modifying its properties triggers getter or setter, which are opaque and may have side effects. UglifyJS lacks complete program flow analysis. It can simple judge whether a variable is later referenced or modified but cannot determine the complete modification process of a variable. It doesn’t know if it points to an external variable, so many potentially side-effect-causing code cannot be removed. Rollup has the ability to perform program flow analysis, making it better at determining whether code truly has side effects. However, these issues were prevalent in older versions. The current Webpack tree shaking has undergone many optimizations and can perform sufficient program flow analysis for tree shaking. The purpose of Webpack’s tree shaking is to mark unused exported members as unused and not export them in the modules where they are re-exported. It sounds complicated, but looking at the code makes it clearer: // a.js export function a() &#123;&#125; // b.js export function b()&#123;&#125; // package/index.js import a from './a' import b from './b' export &#123; a, b &#125; // app.js import &#123;a&#125; from 'package' console.log(a) When using app.js as the entry point, the code after tree shaking becomes: // a.js export function a() &#123;&#125; // b.js is no longer exported: function b()&#123;&#125; function b() &#123;&#125; // package/index.js does not export module b anymore import a from './a' import './b' export &#123; a &#125; // app.js import &#123;a&#125; from 'package' console.log(a) After combining Webpack’s scope hoisting and uglify, all traces of module b will be completely eliminated. But what if module b contains some side effects, such as a simple log: // b.js export function b(v) &#123; return v &#125; console.log(b(1)) After webpack, the content of module `b` becomes: // b.js console.log(function (v)&#123;return v&#125;(1)) Although the export of module b is ignored, the code with side effects is retained. Due to various strange operations introduced by the transformer after compilation, which may cause side effects, we often find that even with tree shaking, our bundle size doesn’t significantly decrease. Usually, we expect that if module b is not being used, none of its code should be included. This is where the role of sideEffects becomes apparent: if the imported package/module is marked as &quot;sideEffects: false&quot;, regardless of whether it truly has side effects, as long as it’s not being referenced, the entire module/package will be completely removed. Taking mobx-react-devtools as an example, we often use it like this: import DevTools from 'mobx-react-devtools'; class MyApp extends React.Component &#123; render() &#123; return ( &lt;div> ... &#123; process.env.NODE_ENV === 'production' ? null : &lt;DevTools /> &#125; &lt;/div> ); &#125; &#125; This is a common scenario of importing modules on demand. However, without the sideEffects: false configuration, even if NODE_ENV is set to production, the bundled code will still include the mobx-react-devtools package. Although we haven’t used any of its exported members, mobx-react-devtools will still be imported because it “might” have side effects. But when we add sideEffects: false, tree shaking can safely remove it entirely from the bundle. Use Cases of sideEffects As mentioned earlier, it’s often difficult to guarantee whether packages/modules published on npm contain side effects (it could be the code’s fault or the transformer’s fault). However, we can usually ensure whether a package/module will affect objects outside of it, such as modifying properties on the window object or overwriting native object methods. If we can guarantee this, we can determine whether a package can have &quot;sideEffects: false&quot;. Whether it truly has side effects is not that important for Webpack; it’s acceptable as long as it’s marked. This explains why packages with inherent side effects, like vue, can still have &quot;sideEffects: false&quot; applied. So, in Webpack, &quot;sideEffects: false&quot; doesn’t mean that the module truly has no side effects. It’s just a way to tell Webpack during tree shaking: “I designed this package with the expectation that it has no side effects, even if it ends up having side effects after being bundled.”","link":"/2023/10/27/en/Webpack-optimization-3/"},{"title":"Understanding Ajax and Cross-Origin Requests Easily","text":"Introduction When learning to write web pages, you usually start with HTML and CSS, which are responsible for creating and beautifying the layout. Once you have a solid foundation, you start learning JavaScript to create interactive effects. In addition to user and browser interactions, don’t forget about the interaction between the client and server, which means you must learn how to use JavaScript to retrieve data from the backend server. Otherwise, your web page data will be static. The main target audience of this article is beginners in web front-end development. I hope that after reading this article, readers who do not understand how to exchange data with the server or how to connect to APIs can have a better understanding of how to connect to the backend. Let’s start with an example Before we begin, let’s consider a question: Why does the front-end need to exchange data with the backend? Actually, this depends on the type of web page you are creating. If you are creating an official website, the entire website is likely to be static, and only HTML and CSS are required, without the need to retrieve data from the backend server. Let’s assume that today we want to create a web page that can browse the current Twitch live stream list, as shown below. If this web page does not retrieve data from the backend, it means that the content of the web page is fixed and will remain the same no matter when it is viewed. However, this is not correct because the goal of this web page is to display “channels that are currently live,” so the content will change accordingly. Since the content will change, we must continuously update the data, retrieve data from the server, and then display it after processing it on the front-end. After confirming the need to retrieve data, we can ask ourselves two questions: Who do we retrieve data from? How do we retrieve data? The answer to the first question is obviously Twitch because Twitch has the data we need! As for the second question, we must use the Twitch API. API What is an API? You may have heard this term many times, but still don’t know what it means. Let’s start with its full name, which is “Application Programming Interface.” You may wonder what this is and why I can’t understand it in both Chinese and English. But actually, the most important thing in these few words is the word “interface.” What is an interface? An interface is used for connection. I’ll give you an example. Isn’t there a USB slot on your computer? As long as you see USB flash drives on the market, you can buy them and plug them into the USB slot, and your computer can read them. Have you ever wondered why? Although they are made by different manufacturers, they can all be read and plugged into the USB slot. This is because there is a standard called the USB interface. After this standard was established, as long as all manufacturers develop according to this standard, they can ensure that they can connect to the computer and USB flash drives. API is the same, but it becomes a connection between programs. For example, if I need to read a file in my program, how do I read it? Reading files is a function provided by the operating system, so I can connect to the “read file API” and use this function in my program. I’ll give you a few more examples. Suppose I want to allow my web page to log in with Facebook. What should I do? I need to connect to the “Facebook API,” which is a set of standards provided by Facebook to everyone who wants to access Facebook services. Any developer who wants to access Facebook services can follow these standards to obtain the data they want. This thing is called an API. Or maybe you are a developer of a hotel management system today, and your company has developed an ERP for hotels, which can manage the booking status of hotels and so on, and can know which rooms are empty now. If you only use this data yourself, it would be a pity. Therefore, the company decided to provide this data to large booking websites, which can display the room status of this hotel in real-time on those websites. Therefore, data exchange is necessary, and you need to provide a “query room status API” to other websites so that they can connect to it and obtain this information. By now, you should have some sense of what an API is. Let me give you a few more examples: I want to retrieve photos from Flickr, so I need to connect to the Flickr API. Google wants to allow other apps to log in and authenticate with Google, so Google needs to provide the “Google login API.” I want to retrieve the channels currently available on Twitch, so I need to connect to the Twitch API. API Documentation Now that we know what an API is and that we need to connect to it, the next question is “how do we connect?” Earlier, we mentioned an example of file access. This is actually more like calling a function provided by the operating system or a programming language library. You can usually find more detailed information about these functions in the official documentation, such as reading files in Node.js: (Source: https://nodejs.org/api/fs.html#fs_fs_readdir_path_options_callback) Above, it is written which function you should call and what parameters you should pass in. API integration is the same. You must have documentation to know how to integrate, otherwise you cannot integrate at all because you don’t even know what parameters to pass. Let’s take a look at how the Twitch API documentation is written. It explains that you must have a Client ID, and the API Root URL is https://api.twitch.tv/kraken, etc. These are basic information related to the API. If you click on any API in the left column, you will see detailed information about each API: Here, it is written what the URL is, what parameters you should pass, etc. There are also reference examples below, which is a very complete API documentation. Usually, when writing web pages, we directly talk about APIs, but actually we are referring to Web APIs, which are APIs transmitted through the network. Are there non-Web APIs? Yes, like the file reading API we mentioned earlier, they are all executed locally on the computer without going through any network. But this doesn’t really matter, everyone is used to talking about APIs, as long as they can understand it. Now that we have the API documentation, we have all the information we need. Using the Twitch example above, as long as we can send a request to https://api.twitch.tv/kraken/games/top?client_id=xxx through JavaScript, Twitch will return the current list of the most popular games. We have narrowed down the scope of the problem step by step. At first, it was “how to get data from Twitch”, and now it is divided into: “how to use JavaScript to send a request”. Ajax To send a request on the browser, you must use a technology called Ajax, which stands for “Asynchronous JavaScript and XML”, with the emphasis on the word “Asynchronous”. Before talking about what is asynchronous, let’s first mention what is synchronous. Almost all JavaScript you originally wrote is executed synchronously. This means that when it executes to a certain line, it will wait for this line to finish executing before executing the next line, ensuring the execution order. That is to say, the last line of the following code needs to wait for a long time to be executed: var count = 10000000; while(count--) &#123; // Do some time-consuming operations &#125; // Executed after a long time console.log('done') It looks reasonable. Isn’t the program executed line by line? But if it involves network operations, everyone can think about the following example: // Assuming there is a function called sendRequest to send a request var result = sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx'); // Executed after a long time console.log(result); When JavaScript executes sendRequest, because it is synchronous, it will wait for the response to come back before continuing to do anything. In other words, before the response comes back, the entire JavaScript engine will not execute anything! It’s scary, isn’t it? You click on anything related to JavaScript, and there is no response because JavaScript is still waiting for the response. Therefore, for operations that are expected to be very time-consuming and unstable, synchronous execution cannot be used, but asynchronous execution must be used. What does asynchronous mean? It means that after it is executed, it will not be taken care of, and it will continue to execute the next line without waiting for the result to come back: // Assuming there is a function called sendRequest to send a request var result = sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx'); // The above request is executed, and then it executes to this line, so result will not have anything // because the response has not returned yet console.log(result); Please note that “asynchronous functions cannot directly return results through return”. Why? Because, as in the example above, after sending a request, the next line will be executed, and at this time, there is no response yet. What should be returned? So what should we do? Let me give you a very common example! When I was eating in a food court in Singapore, there was a table number on each table. When you order, just tell the boss which table you are sitting at, and the boss will deliver it to you after the meal is ready. So I don’t need to stand at the door of the store and wait. I just continue to sit on my own things. Anyway, the boss will deliver it to me after the meal is ready. The concept of asynchronous is also like this. After I send a request (after I order), I don’t need to wait for the response to come back (I don’t need to wait for the boss to finish), I can continue to do my own thing. After the response comes back (after the meal is ready), it will help me deliver the result (the boss will deliver it by himself). In the ordering example, the boss can know where to send the data through the table number. What about in JavaScript? Through Function! And this function, we call it a Callback Function, a callback function. When the asynchronous operation is completed, this function can be called and the data can be brought in. // Assuming there is a function called sendRequest to send a request sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx', callMe); function callMe (response) &#123; console.log(response); &#125; // Or write it as an anonymous function sendRequest('https://api.twitch.tv/kraken/games/top?client_id=xxx', function (response) &#123; console.log(response); &#125;); Now you know why network operations are asynchronous and what callback functions are. XMLHttpRequest Just mentioned the concepts of Ajax, asynchronous, and callback functions, but didn’t say how to send a request, just wrote a fake sendRequest function as a reference. To send a request, we need to use an object prepared by the browser called XMLHttpRequest. The sample code is as follows: var request = new XMLHttpRequest(); request.open('GET', `https://api.twitch.tv/kraken/games/top?client_id=xxx`, true); request.onload = function() &#123; if (request.status >= 200 &amp;&amp; request.status &lt; 400) &#123; // Success! console.log(request.responseText); &#125; &#125;; request.send(); The request.onload above actually specifies which function to use to handle the data when it comes back. With the above code, you have finally succeeded and can finally connect to the Twitch API and get data from there! It’s really gratifying. From now on, you will live a happy life with the skill of “connecting to the API”… Not really. Same Origin Policy Just when you thought you were already familiar with connecting to APIs and wanted to try connecting to other APIs, you found that a problem occurred with just one line: XMLHttpRequest cannot load http:&#x2F;&#x2F;odata.tn.edu.tw&#x2F;ebookapi&#x2F;api&#x2F;getOdataJH&#x2F;?level&#x3D;all. No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource. Origin &#39;null&#39; is therefore not allowed access. Huh? Why is there this error? In fact, for security reasons, the browser has something called the Same-origin policy. This means that if the website you are currently on and the API website you want to call are “different sources”, the browser will still help you send the request, but it will block the response, preventing your JavaScript from receiving it and returning an error. What is a different source? Simply put, if the domain is different, it is a different source, or if one uses http and the other uses https, or if the port numbers are different, it is also a different source. So if you are using someone else’s API, in most cases it will be a different source. I want to emphasize here that “your request is still sent”, and the browser “does receive the response”, but the key point is that “due to the same-origin policy, the browser does not pass the result back to your JavaScript”. If there is no browser, there is actually no such problem. You can send it to whoever you want and get the response no matter what. Okay, since we just said that different sources will be blocked, how did we successfully connect to the Twitch API? CORS As we all know, it is very common to transfer data between different sources, just like we connect to the Twitch API. How can we be under the same domain as the Twitch API? Therefore, the same-origin policy does regulate that non-same-origin requests will be blocked, but at the same time, there is another regulation that says: “If you want to transfer data between different origins, what should you do?” This regulation is called CORS. CORS, short for Cross-Origin Resource Sharing, is a cross-origin resource sharing protocol. This protocol tells you that if you want to open cross-origin HTTP requests, the server must add Access-Control-Allow-Origin to the response header. You should be familiar with this field. If you feel unfamiliar, you can go back and look at the error message just now, which actually mentioned this header. After the browser receives the response, it will first check the content of Access-Control-Allow-Origin. If it contains the origin of the request that is currently being initiated, it will allow it to pass and allow the program to receive the response smoothly. If you carefully check the request we sent to Twitch in the beginning, you will find that the header of the response is roughly like this: Content-Type: application&#x2F;json Content-Length: 71 Connection: keep-alive Server: nginx Access-Control-Allow-Origin: * Cache-Control: no-cache, no-store, must-revalidate, private Expires: 0 Pragma: no-cache Twitch-Trace-Id: e316ddcf2fa38a659fa95af9012c9358 X-Ctxlog-Logid: 1-5920052c-446a91950e3abed21a360bd5 Timing-Allow-Origin: https:&#x2F;&#x2F;www.twitch.tv The key point is this line: Access-Control-Allow-Origin: *, where the asterisk represents a wildcard character, meaning that any origin is accepted. Therefore, when the browser receives this response, it compares the current origin with the * rule, passes the verification, and allows us to accept the response of the cross-origin request. In addition to this header, there are actually others that can be used, such as Access-Control-Allow-Headers and Access-Control-Allow-Methods, which can define which request headers and methods are accepted. To sum up, if you want to initiate a cross-origin HTTP request and receive a response smoothly, you need to ensure that the server side has added Access-Control-Allow-Origin, otherwise the response will be blocked by the browser and an error message will be displayed. Preflight Request Do you still remember Twitch’s API documentation? It requires a client-id parameter, and the document says that you can pass it in the GET parameter or in the header. Let’s try passing it in the header! Open Devtool, and you will see a magical phenomenon: Huh? I clearly only sent one request, why did it become two? And the method of the first one is actually OPTIONS. Why did adding one header result in an extra request? In fact, this is also related to CORS mentioned above. CORS divides requests into two types, one is a simple request. What is a simple request? There is actually a long definition, which I think you can read when you need it. But in short, if you don’t add any custom headers, and it’s a GET request, it’s definitely a simple request (isn’t this simple enough?). On the contrary, if you add some custom headers, such as the Client-ID we just added, this request is definitely not a simple request. (Definition reference: MDN: Simple Request) From the above classification, we know that the request we just initiated is not a simple request because it has a custom header. So why is there an extra request? This request is called a Preflight Request, which is used to confirm whether subsequent requests can be sent because non-simple requests may contain some user data. If this Preflight Request fails, the real request will not be sent, which is the purpose of the Preflight Request. Let me give you an example, and you will know why this Preflight Request is needed. Assuming that a server provides an API URL called: https://example.com/data/16, you can get the data with id 16 by sending a GET request to it, and you can delete this data by sending a DELETE request to it. If there is no Preflight Request mechanism, I can send a DELETE request to this API on any web page of any domain. As I emphasized earlier, the browser’s CORS mechanism will still help you send the request, but only the response will be blocked by the browser. Therefore, even though there is no response, the server did receive this request, so it will delete this data. If there is a Preflight Request, when receiving the result of the request, it will know that this API does not provide CORS, so the real DELETE request will not be sent, and it will end here. The purpose of the Preflight Request is to use an OPTIONS request to confirm whether the subsequent request can be sent. JSONP Finally, let’s talk about JSONP, which is another method for cross-origin requests besides CORS, called JSON with Padding. Do you remember the same-origin policy mentioned at the beginning? If you think about it carefully, you will find that some things are not restricted by the same-origin policy, such as the &lt;script&gt; tag. Don’t we often refer to third-party packages such as CDN or Google Analytics on web pages? The URLs are all from other domains, but they can be loaded normally. JSONP uses this feature of &lt;script&gt; to achieve cross-origin requests. Imagine you have an HTML like this: &lt;script> var response = &#123; data: 'test' &#125;; &lt;/script> &lt;script> console.log(response); &lt;/script> It’s a very easy-to-understand piece of code, so I won’t explain it much. What if you replace the above code with a URL? &lt;script src=\"https://another-origin.com/api/games\">&lt;/script> &lt;script> console.log(response); &lt;/script> If the content returned by https://another-origin.com/api/games is the same as before: var response = &#123; data: 'test' &#125;; Then can’t I get the data in the same way? And these data are still controlled by the server, so the server can give me any data. But using global variables like this is not very good. We can use the concept of Callback Function just mentioned and change it to this: &lt;script> receiveData(&#123; data: 'test' &#125;); &lt;/script> &lt;script> function receiveData (response) &#123; console.log(response); &#125; &lt;/script> So what is JSONP? JSONP actually uses the above format to put data in &lt;script&gt; and bring the data back through the specified function. If you think of the first &lt;script&gt; as the server’s return value, you will understand. In practice, when operating JSONP, the server usually provides a callback parameter for the client to bring over. The Twitch API provides a JSONP version, and we can directly look at the example. URL: https://api.twitch.tv/kraken/games/top?client_id=xxx&amp;callback=aaa&amp;limit=1 aaa(&#123;\"_total\":1069,\"_links\":&#123;\"self\":\"https://api.twitch.tv/kraken/games/top?limit=1\",\"next\":\"https://api.twitch.tv/kraken/games/top?limit=1\\u0026offset=1\"&#125;,\"top\":[&#123;\"game\":&#123;\"name\":\"Dota 2\",\"popularity\":63361,\"_id\":29595,\"giantbomb_id\":32887,\"box\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-272x380.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-136x190.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-52x72.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"logo\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-240x144.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-120x72.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-60x36.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"_links\":&#123;&#125;,\"localized_name\":\"Dota 2\",\"locale\":\"zh-tw\"&#125;,\"viewers\":65243,\"channels\":373&#125;]&#125;) URL: https://api.twitch.tv/kraken/games/top?client_id=xxx&amp;callback=receiveData&amp;limit=1 receiveData(&#123;\"_total\":1067,\"_links\":&#123;\"self\":\"https://api.twitch.tv/kraken/games/top?limit=1\",\"next\":\"https://api.twitch.tv/kraken/games/top?limit=1\\u0026offset=1\"&#125;,\"top\":[&#123;\"game\":&#123;\"name\":\"Dota 2\",\"popularity\":63361,\"_id\":29595,\"giantbomb_id\":32887,\"box\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-272x380.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-136x190.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-52x72.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-boxart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"logo\":&#123;\"large\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-240x144.jpg\",\"medium\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-120x72.jpg\",\"small\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-60x36.jpg\",\"template\":\"https://static-cdn.jtvnw.net/ttv-logoart/Dota%202-&#123;width&#125;x&#123;height&#125;.jpg\"&#125;,\"_links\":&#123;&#125;,\"localized_name\":\"Dota 2\",\"locale\":\"zh-tw\"&#125;,\"viewers\":65622,\"channels\":376&#125;]&#125;) Have you noticed? It passes the callback parameter you brought over as the function name and passes the entire JavaScript object to the Function, so you can get the data inside the Function. Combined, it would look like this: &lt;script src=\"https://api.twitch.tv/kraken/games/top?client_id=xxx&amp;callback=receiveData&amp;limit=1\">&lt;/script> &lt;script> function receiveData (response) &#123; console.log(response); &#125; &lt;/script> Using JSONP, you can also access cross-origin data. However, the disadvantage of JSONP is that the parameters you need to pass can only be passed through the URL in a GET request, and cannot be passed through a POST request. If CORS can be used, it should be prioritized over JSONP. Summary The content of this article starts with the process of fetching data and tells you step by step where to fetch it and how to fetch it. If you want to fetch data using an API, what is an API? How to call Web API in JavaScript? How to access cross-origin data? Generally speaking, I have mentioned everything related to fetching data with the front-end, but there is a regret that I did not mention the Fetch API, which is a newer standard used to fetch data. The introduction on MDN is: The Fetch API provides an interface for fetching resources (including across the network). It will seem familiar to anyone who has used XMLHttpRequest, but the new API provides a more powerful and flexible feature set. Interested readers can check it out for themselves. I hope that after reading this article, you will have a better understanding of how to connect to the back-end API and the difficulties you may encounter when connecting.","link":"/2017/08/27/en/ajax-and-cors/"},{"title":"pack-tool-preview","text":"I tried migrating a real project from Vite to Rspack. The build time reduced from 125 seconds to 17 seconds, and the page refresh speed during development increased by 64%. However, the HMR (Hot Module Replacement) in Rspack is much slower compared to Vite. If you frequently trigger HMR during development and refresh the page less often, Vite still offers a better development experience. For complex projects where refreshing the page is more common, Rspack provides a better development experience. There are so many frontend build tools out there: RollDown, Rollup, Rspack, Vite… Just a sneak peek; stay tuned for the detailed comparison.","link":"/2023/10/27/en/pack-tool-preview/"},{"title":"Vue Proxy and Reflect","text":"Introduction Since Vue.js 3’s reactive data is based on Proxy, it’s essential to understand Proxy and its associated concept, Reflect. What is Proxy? In simple terms, Proxy allows you to create a proxy object. It can proxy other objects, emphasizing that Proxy can only proxy objects and not non-object values like strings, booleans, etc. So, what does proxying mean? Proxying refers to the act of creating a basic semantic representation of an object. It allows us to intercept and redefine the basic operations on an object. Create object proxies with Proxy Built-in object Reflect When we talk about “basic semantics” in programming languages, we mean the fundamental operations for reading and modifying data. In JavaScript, these operations typically include reading property values and setting property values. For example, given an object obj, the following operations are considered basic semantics: Read property value: obj.foo (reads the value of property foo) Set property value: obj.foo = newValue (sets the value of property foo) In the above code, Proxy objects allow us to intercept (or redefine) these basic semantic operations. The Proxy constructor takes two parameters: the object being proxied and an object containing interceptors (also known as traps). In the interceptor object, we can define the get method to intercept property read operations and the set method to intercept property set operations. This way, we can execute custom logic when these operations occur. Understanding these basic semantic operations and how to use Proxy and Reflect to intercept and handle them is crucial for implementing reactive data in JavaScript. In reactive data, we can use Proxy and Reflect to track reads and modifications of object properties, enabling reactive updates of data. Basic Usage of Proxy When we talk about basic semantics, we refer to fundamental operations in JavaScript, such as reading object property values and setting object property values. Consider the following object obj: const obj = &#123; foo: 1 &#125;; Here, obj.foo is a basic semantic operation for reading property values, and obj.foo = newValue is a basic semantic operation for setting property values. Now, we can use Proxy to intercept these basic semantic operations. const handler = &#123; get(target, key) &#123; console.log(`Reading property $&#123;key&#125;`); return target[key]; &#125;, set(target, key, value) &#123; console.log(`Setting property $&#123;key&#125; to $&#123;value&#125;`); target[key] = value; &#125; &#125;; const proxyObj = new Proxy(obj, handler); proxyObj.foo; // Outputs: Reading property foo proxyObj.foo = 2; // Outputs: Setting property foo to 2 In the above code, we created a handler object that defines get and set methods to intercept property reads and sets. Then, we created a proxy object proxyObj using the Proxy constructor, which intercepts read and set operations on the obj object. When we access proxyObj.foo, the get method is triggered, outputting the corresponding message. When we set the value of proxyObj.foo, the set method is triggered, again outputting the corresponding message. This way, Proxy allows us to execute custom logic when basic semantic operations occur, without directly manipulating the original object. In practical applications, this capability can be used to implement reactive data, data validation, logging, and more. When intercepting object property reads with Proxy, special attention is required for accessor properties because accessor properties are defined using getter functions. The this keyword inside these getter functions changes based on the method of invocation. To solve this issue, we use Reflect.get(target, key, receiver) instead of target[key] when accessing property values. This ensures that the receiver parameter correctly points to the proxy object, not the original object. Consequently, within the getter function of accessor properties, the this keyword refers to the proxy object, establishing the correct reactive relationship. Here is the corrected code using Reflect.get: const handler = &#123; get(target, key, receiver) &#123; track(target, key); // Reactive data dependency tracking return Reflect.get(target, key, receiver); // Use Reflect.get to get property value &#125;, // Other interceptor methods... &#125;; const proxyObj = new Proxy(obj, handler); effect(() => &#123; console.log(proxyObj.bar); // Access the bar property inside the side effect function &#125;); proxyObj.foo++; // Triggers re-execution of the side effect function In this code, we use Reflect.get with the receiver parameter to ensure that this points to the proxy object within the get interceptor function. This establishes the correct reactive relationship, allowing proper dependency tracking when accessing object properties. Usage of Reflect in Reactivity In interceptor functions, we aim to establish a connection between side-effect functions and reactive data. This ensures that when properties are accessed, the correct dependencies are tracked, enabling re-execution of side-effect functions when properties change. However, if we directly use target[key] to access property values, the this keyword inside the getter function of accessor properties points to the original object, not the proxy object. This prevents the establishment of the correct reactive relationship. To address this issue, we use Reflect.get(target, key, receiver) instead of target[key]. By doing so, the receiver parameter correctly points to the proxy object, allowing the this keyword inside the getter function to refer to the proxy object. This establishes the proper reactive relationship. Here is an example demonstrating the use of the receiver parameter and comparing it with the scenario where the receiver parameter is not used: 1. Using the receiver parameter: const data = &#123; foo: 1 &#125;; const proxy = new Proxy(data, &#123; get(target, key, receiver) &#123; // Use Reflect.get to ensure `this` points to the proxy object const result = Reflect.get(target, key, receiver); // Additional processing, such as triggering update operations, can be performed in practical applications console.log(`Accessed $&#123;key&#125; property with value $&#123;result&#125;`); return result; &#125; &#125;); console.log(proxy.foo); // Outputs: Accessed foo property with value 1 In this example, we use the receiver parameter passed to Reflect.get to ensure that this inside the get interceptor function refers to the proxy object proxy. When you access proxy.foo, the get interceptor function is triggered, and this points to the proxy object. 2. Not using the receiver parameter: const data = &#123; foo: 1 &#125;; const proxy = new Proxy(data, &#123; get(target, key) &#123; // Without using the receiver parameter, 'this' refers to the original object 'data' const result = target[key]; // In practical applications, additional processing might be required, such as triggering update operations console.log(`Accessed $&#123;key&#125; property with value $&#123;result&#125;`); return result; &#125; &#125;); console.log(proxy.foo); // Output: Accessed foo property with value 1 In this example, we did not use the receiver parameter. Since the receiver parameter was not passed, this inside the get interceptor function points to the original object data. Although the proxy object proxy is used, the this inside the get interceptor function does not refer to proxy but instead refers to the original object data. Therefore, in this scenario, the reactive relationship is not established. While the output of the two functions is the same, it’s evident that without using the receiver parameter, the reactive relationship is not established. This means that within the effect function, the object will not receive the correct reactivity.","link":"/2023/11/01/en/vue-Proxy-and-Reflect/"},{"title":"Nested Effects and Effect Stack","text":"Introduction Effect functions can be nested. But why is this design choice made? Nested Effects effect(function effectFn1() &#123; effect(function effectFn2() &#123; /* ... */ &#125;) /* ... */ &#125;) In the code above, effectFn1 is nested within effectFn2. The execution of effectFn1 will trigger the execution of effectFn2. So, when do we encounter nested effects? Take Vue.js, for example; Vue.js’s rendering function is executed within an effect. When components are nested, for instance, when the Foo component renders the Bar component: // Bar component const Bar = &#123; render() &#123;/* ... */ &#125;, &#125; // Foo component renders the Bar component const Foo = &#123; render() &#123; return &lt;Bar /> &#125;// JSX syntax &#125; Nested effects occur in this scenario. It can be visualized as follows: effect(() => &#123; Foo.render() // Nested effect(() => &#123; Bar.render()&#125; )&#125; ) The effect function can be nested, meaning an effect function can contain another effect function. When an outer effect function depends on reactive data created inside an inner effect function, the inner effect function is automatically tracked, ensuring that the outer effect function is executed when the inner effect function changes. This nested structure of effect functions establishes a dependency chain, ensuring that when reactive data changes, all the effect functions dependent on it are triggered, thereby maintaining the responsiveness of the application. The “effect stack” in Vue 3’s internal implementation is crucial. Vue uses an effect stack to track the currently executing effect functions, similar to a function call stack. This stack manages the execution order and dependency relationships of effect functions. Now, let’s consider an example of a nested effect function without using a stack structure. However, it cannot achieve the desired nesting functionality. Let’s assume we have two reactive data, count1 and count2, where the value of count2 depends on the value of count1. We can use nested effect functions to establish this dependency relationship. // Original data const data = &#123; foo: true, bar: true &#125;; // Proxy object const obj = new Proxy(data, &#123; get(target, key) &#123; console.log(`Reading property: $&#123;key&#125;`); return target[key]; &#125; &#125;); // Global variables let temp1, temp2; // effectFn1 is nested within effectFn2 effect(function effectFn1() &#123; console.log('effectFn1 executed'); effect(function effectFn2() &#123; console.log('effectFn2 executed'); // Access obj.bar property within effectFn2 temp2 = obj.bar; &#125;); // Access obj.foo property within effectFn1 temp1 = obj.foo; &#125;); effectFn1 is the outer effect function, which depends on the value of obj.foo. It contains an innerEffect within it. The inner effect function, effectFn2, depends on the value of obj.bar. When we modify obj.foo, the outer effect function should be triggered and output the value of obj.foo. When we modify obj.bar, the inner effect function should be triggered and output the value of obj.bar. We use the global variable activeEffect to store the effect functions registered through the effect function. This means that at any given time, activeEffect stores only one effect function. // Use a global variable to store the currently active effect function let activeEffect; function effect(fn) &#123; // Define the effect function const effectFn = () => &#123; // Call the cleanup function; specific implementation needs to be provided based on requirements cleanup(effectFn); // Assign the effect function to activeEffect activeEffect = effectFn; // Execute the effect function fn(); // Store the dependencies of the current effect function in effectFn.deps (Needs to be implemented based on the actual logic) effectFn.deps = []; // Set dependencies collection based on the actual logic &#125;; // Execute the effect function effectFn(); &#125; However, by only using a single variable for storage without employing a stack structure, when nested effects occur, the execution of the inner effect function will overwrite the value of activeEffect. It will never be restored to its original value. If there is a reactive data performing dependency collection, even if it is read within the outer effect function, the collected effect functions will all be from the inner effect function. In other words, when I read obj.foo, activeEffect still refers to the value of innerEffect, and only the innerEffect is triggered. To solve this issue, we need an effect function stack called effectStack. When an effect function is executed, the current effect function is pushed onto the stack. After the execution of the effect function is completed, it is popped from the stack. The activeEffect is always set to the top effect function on the stack. This ensures that a reactive data will only collect the effect function that directly reads its value, preventing mutual interference: // Use a global variable to store the currently active effect function let activeEffect; // Effect stack const effectStack = []; function effect(fn) &#123; const effectFn = () => &#123; cleanup(effectFn); // Call the cleanup function; specific implementation needs to be provided based on requirements activeEffect = effectFn; // Push the current effect function onto the stack effectStack.push(effectFn); fn(); // After the execution of the current effect function is completed, pop it from the stack, and restore activeEffect to its previous value effectStack.pop(); activeEffect = effectStack[effectStack.length - 1]; &#125;; // Initialize the dependencies collection of the effect function effectFn.deps = []; // Execute the effect function effectFn(); &#125;","link":"/2023/10/31/en/vue-effect/"},{"title":"vue-expired-side-effects","text":"Introduction When we talk about race conditions, it typically refers to a concurrency problem in multi-process or multi-threaded programming. However, in frontend development, we might not directly encounter multi-threaded programming frequently, but we often face similar situations related to race conditions. A common example is in asynchronous programming, especially when dealing with asynchronous events, callback functions, or Promises. For instance, consider the following asynchronous code: let data; function fetchData() &#123; setTimeout(() => &#123; data = 'Fetched data'; &#125;, 1000); &#125; fetchData(); console.log(data); // Outputs undefined In this example, the fetchData function is asynchronous, and it assigns the data to the data variable after 1 second. However, due to JavaScript’s single-threaded nature, the fetchData function waits in the main thread’s event queue for 1 second. Within this 1 second, the console.log(data) statement executes immediately, and at that point, the value of data is undefined because the fetchData function has not completed yet. In asynchronous programming, due to the non-blocking nature of the code, similar race condition issues can arise. When dealing with asynchronous operations, it’s crucial to ensure data consistency and correctness, avoiding accessing or modifying related data before the asynchronous operation is completed. Race Conditions and Reactivity So, how are race conditions related to reactivity? Consider the following example: let finalData; watch(obj, async () => &#123; // Send and wait for a network request const res = await fetch('/path/to/request'); // Assign the request result to data finalData = res; &#125;); In this code snippet, we use the watch function to observe changes to the obj object. Every time the obj object changes, a network request, such as an API call, is sent. After the data request is successful, the result is assigned to the finalData variable. At first glance, this code might seem fine. However, upon closer inspection, you’ll realize that this code can lead to race condition problems. Let’s assume we modify a field of the obj object for the first time, triggering the callback function and sending the first request A. As time passes, before the result of request A returns, we modify a field of the obj object again, triggering the second request B. Now, both request A and request B are in progress. Which request will return its result first? We don’t know. If request B completes before request A, the finalData variable will store the result of request B, making request A’s result outdated. However, because request B was sent later, we consider its data as the “latest.” Request A is deemed “expired,” and its result should be invalidated. By ensuring that request B’s result is considered the latest, we can prevent errors caused by race conditions. Essentially, what we need is a way to expire side effects. To illustrate this concept further, let’s replicate the scenario using the watch function in Vue.js to see how Vue.js helps developers address this problem. Later, we’ll attempt to implement this functionality ourselves. watch(obj, async (newValue, oldValue, onInvalidate) => &#123; // Define a flag to indicate whether the current side effect has expired, initially set to false (not expired) let expired = false; // Call the onInvalidate() function to register an expiration callback onInvalidate(() => &#123; // When expired, set the expired flag to true expired = true; &#125;); // Send a network request const res = await fetch('/path/to/request'); // Perform subsequent operations only if the side effect has not expired if (!expired) &#123; finalData = res; // Subsequent operations... &#125; &#125;); As shown in the code above, before sending the request, we define an expired flag variable to indicate whether the current side effect has expired. We then call the onInvalidate function to register an expiration callback. When the side effect expires, the expired flag is set to true. Finally, we use the request result only if the side effect has not expired, effectively avoiding the issue described earlier.","link":"/2023/11/01/en/vue-expired-side-effects/"},{"title":"The Role and Implementation of Vue.js Reactive System","text":"Introduction The concept of reactivity is not difficult to understand. It refers to triggering certain events when JavaScript operates on an object or a value. This is achieved by implementing a reactive system, where operations elicit specific responses. Reactive Data and Side Effect Functions Side effect functions refer to functions that produce side effects. Consider the following code snippet: function effect() &#123; document.body.innerText = 'hello vue3'; &#125; When the effect function is executed, it sets the text content of the body. Any function other than effect can read or modify the body’s text content. In other words, the execution of the effect function directly or indirectly affects the execution of other functions, indicating that the effect function has side effects. Side effect functions are common and can impact various aspects, such as the effectiveness of “tree shaking” in webpack, a topic we discussed earlier. I won’t delve into this here. Side effects can easily occur; for example, if a function modifies a global variable, it creates a side effect, as shown in the following code: // Global variable let val = 1; function effect() &#123; val = 2; // Modifying a global variable creates a side effect &#125; Understanding side effect functions, let’s now discuss reactive data. Suppose a property of an object is read within a side effect function: const obj = &#123; text: 'hello world' &#125;; function effect() &#123; // The execution of the effect function reads obj.text document.body.innerText = obj.text; &#125; The side effect function effect sets the innerText property of the body element to obj.text. When the value of obj.text changes, we want the side effect function effect to re-execute. Our approach is as follows: we want to store the effect function in a bucket when reading the obj.text value, and when setting the obj.text value, we want to retrieve the effect function from the bucket and execute it. Basic Implementation of Reactive Data How can we make obj reactive data? By observing, we find that: When the side effect function effect is executed, it triggers the read operation of the obj.text property. When the obj.text value is modified, it triggers the write operation of the obj.text property. We need to intercept the read and write operations of an object property. Before ES2015, this could only be done using the Object.defineProperty function, which was also the approach used in Vue.js 2. In ES2015 and later, we can use the Proxy object to achieve this, and this is the approach adopted in Vue.js 3. function createReactiveObject(target, proxyMap, baseHandlers) &#123; // The core is the proxy // The goal is to detect user get or set actions const existingProxy = proxyMap.get(target); if (existingProxy) &#123; return existingProxy; &#125; const proxy = new Proxy(target, baseHandlers); // Store the created proxy, proxyMap.set(target, proxy); return proxy; &#125; Here, we create a reactive object based on the Proxy object. We have a proxyMap, which is a container for storing various types of proxies. We define get and set intercept functions to intercept read and write operations. Designing a Comprehensive Reactive System From the above examples, it’s clear that the workflow of a reactive system is as follows: When a read operation occurs, collect the side effect functions into a “bucket”. When a write operation occurs, retrieve the side effect functions from the “bucket” and execute them. Next, I’ll explain the principles through a simple implementation of a reactive system. We know that the Proxy object can accept an object with getters and setters for handling get or set operations. Therefore, we can create a baseHandlers to manage getters and setters. // baseHandlers function createGetter(isReadonly = false, shallow = false) &#123; return function get(target, key, receiver) &#123; const res = Reflect.get(target, key, receiver); if (!isReadonly) &#123; // Collect dependencies when triggering get track(target, \"get\", key); &#125; return res; &#125;; &#125; function createSetter() &#123; return function set(target, key, value, receiver) &#123; const result = Reflect.set(target, key, value, receiver); // Trigger dependencies when setting values trigger(target, \"set\", key); return result; &#125;; &#125; We also need to establish a clear link between side effect functions and the target fields being operated upon. For instance, when reading a property, it doesn’t matter which property is being read; all side effect functions should be collected into the “bucket.” Similarly, when setting a property, regardless of which property is being set, the side effect functions from the “bucket” should be retrieved and executed. There is no explicit connection between side effect functions and the operated fields. The solution is simple: we need to establish a connection between side effect functions and the operated fields. This requires redesigning the data structure of the “bucket” and cannot be as simple as using a Set type for the “bucket.” We use WeakMap to implement the bucket for storing effects as discussed earlier. If you are not familiar with the characteristics of the WeakMap class, you can learn more about it here. // Map to store different types of proxies export const reactiveMap = new WeakMap(); export const readonlyMap = new WeakMap(); export const shallowReadonlyMap = new WeakMap(); Once we have defined the buckets as above, we can proceed to implement the core part of the reactive system, which is the proxy: function createReactiveObject(target, proxyMap, baseHandlers) &#123; // The core is the proxy // The goal is to detect user get or set actions const existingProxy = proxyMap.get(target); if (existingProxy) &#123; return existingProxy; &#125; const proxy = new Proxy(target, baseHandlers); // Store the created proxy proxyMap.set(target, proxy); return proxy; &#125; For the previous track and trigger functions: export function track(target, type, key) &#123; if (!isTracking()) &#123; return; &#125; console.log(`Trigger track -> target: $&#123;target&#125; type:$&#123;type&#125; key:$&#123;key&#125;`); // 1. Find the corresponding dep based on the target // Initialize depsMap if it's the first time let depsMap = targetMap.get(target); if (!depsMap) &#123; // Initialize depsMap logic depsMap = new Map(); targetMap.set(target, depsMap); &#125; let dep = depsMap.get(key); if (!dep) &#123; dep = createDep(); depsMap.set(key, dep); &#125; trackEffects(dep); &#125; export function trigger(target, type, key) &#123; // 1. Collect all deps and put them into deps array, // which will be processed later let deps: Array&lt;any> = []; const depsMap = targetMap.get(target); if (!depsMap) return; // Currently only GET type is implemented // for get type, just retrieve it const dep = depsMap.get(key); // Collect into deps array deps.push(dep); const effects: Array&lt;any> = []; deps.forEach((dep) => &#123; // Destructure dep to get the stored effects effects.push(...dep); &#125;); // The purpose here is to have only one dep that contains all effects // Currently, it should be reused for the triggerEffects function triggerEffects(createDep(effects)); &#125;","link":"/2023/10/30/en/vue-reactive-1/"},{"title":"vue-watch-computed","text":"Introduction Previously, we discussed the effect function, which is used to register side-effect functions. It allows specifying options parameters, such as the scheduler to control the timing and manner of side-effect function execution. We also explored the track function for dependency tracking and the trigger function to re-execute side-effect functions. Combining these concepts, we can implement a fundamental and distinctive feature of Vue.js – computed properties. Computed Properties and the lazy Option In Vue.js, the effect function is used to create reactive side-effect functions. By default, side-effect functions passed to effect are executed immediately. For example, in the code below, the side-effect function passed to the effect function is executed immediately: effect(() => &#123; console.log(obj.foo); &#125;); However, in certain cases, we want the side-effect function to execute only when needed, not immediately. A typical scenario is with computed properties. To achieve this delayed execution, we can add a lazy property to the options object and set it to true. When lazy is true, the side-effect function is not executed during initialization but only when necessary. The modified code looks like this: effect( // This function will not execute immediately () => &#123; console.log(obj.foo); &#125;, // options &#123; lazy: true &#125; ); In the implementation, the side-effect function effectFn is returned as the result of the effect function. This means that when we call the effect function, we get the corresponding side-effect function and can manually execute it when needed. This mechanism gives us more control, allowing us to decide when to trigger the execution of the side-effect function rather than executing it immediately. This design pattern is particularly suitable for specific scenarios like computed properties. In computed properties, we might want to trigger the side-effect function’s execution at a specific moment rather than immediately during initialization. By returning the side-effect function from the effect function, we can flexibly control when the side-effect function is executed to meet different requirements in various scenarios. function effect(fn, options = &#123;&#125;) &#123; const effectFn = () => &#123; cleanup(effectFn); activeEffect = effectFn; effectStack.push(effectFn); fn(); effectStack.pop(); activeEffect = effectStack[effectStack.length - 1]; &#125;; // Set options and dependencies for the side-effect function effectFn.options = options; effectFn.deps = []; // Execute the side-effect function only if it's not lazy if (!options.lazy) &#123; effectFn(); &#125; // Return the side-effect function as the result return effectFn; &#125; In this code, the effect function’s second parameter is an options object, where the lazy property is set to true. This means that the side-effect function passed to effect will be executed only when necessary, such as when accessing a computed property. The lazy property allows us to control the immediate execution of the side-effect function. Now that we have achieved lazy computation through computed properties, how do we implement data caching? function computed(getter) &#123; // value is used to cache the last computed value let value; // dirty flag indicates whether a recalculation is needed; if true, it means \"dirty\" and needs computation let dirty = true; const effectFn = effect(getter, &#123; lazy: true &#125;); const obj = &#123; get value() &#123; // Compute the value only if it's \"dirty,\" and cache the computed value in the value variable if (dirty) &#123; value = effectFn(); // Set dirty to false, so the cached value can be used directly next time dirty = false; &#125; return value; &#125; &#125;; return obj; &#125; With lazy computation resolved, the value is calculated only when it is truly needed, executing effectFn only when necessary. Additionally, a dirty flag is introduced to indicate whether the current computation needs to be recalculated. If dirty is true, the value is recalculated, and the dirty flag is set to false so that the cached value can be used directly next time. Implementation Principle of watch The concept of watch essentially involves observing a reactive data and executing the corresponding callback function when the data changes. For example: watch(obj, () => &#123; console.log('Data changed'); &#125;) // Modifying the reactive data triggers the execution of the callback function obj.foo++ Suppose obj is a reactive data, watched using the watch function with a provided callback function. When modifying the reactive data’s value, the callback function is triggered. In fact, the implementation of watch essentially utilizes the effect and the options.scheduler option, as shown in the following code: effect(() => &#123; console.log(obj.foo) &#125;, &#123; scheduler() &#123; // The scheduler function is executed when obj.foo's value changes &#125; &#125;) In a side-effect function accessing the reactive data obj.foo, based on the previous discussion, we know that this establishes a connection between the side-effect function and the reactive data. When the reactive data changes, the side-effect function is re-executed. However, there is an exception: if the side-effect function has a scheduler option, when the reactive data changes, the scheduler function is executed instead of directly triggering the side-effect function. From this perspective, the scheduler function acts as a callback function, and the implementation of watch utilizes this characteristic. Below is the simplest implementation of the watch function: // The watch function receives two parameters: source (reactive data) and cb (callback function) function watch(source, cb) &#123; effect( // Trigger a read operation to establish a connection () => source.foo, &#123; scheduler: scheduler(), // Call the callback function cb when the data changes fn: () => &#123; cb(); &#125;, &#125; ); &#125; In this code, we first define an original data object named data, which contains a property foo with an initial value of 1. Next, we create a proxy object obj using Proxy, intercepting operations on the data. When obj.foo++ is executed, the set interceptor of Proxy is triggered. In the set interceptor, we first set the property value on the target object and then call the watch function, passing obj and a callback function. In the watch function, we use a hypothetical effect function (which might be provided by a framework) to listen for data changes.","link":"/2023/10/31/en/vue-watch-computed/"},{"title":"Webpack Custom Loader/Plugin","text":"Introduction A loader is a node module exported as a function. This function is called when transforming resources in the loader. The given function will utilize the Loader API and can be accessed through the this context. Here is an official link on loader usage and examples, including local development and testing of custom loaders. Simple Usage of Webpack Loader When a loader is used in a resource, it can only take one parameter - a string containing the content of the resource file. Synchronous loaders can return a single value representing the transformed module. Loaders can return one or two values. The first value is a string or buffer containing JavaScript code. The optional second value is a SourceMap, which is a JavaScript object. Here’s a simple example of using a loader. It matches all JavaScript files and processes them using loader.js: // webpack.config.js const path = require('path'); module.exports = &#123; //... module: &#123; rules: [ &#123; test: /\\.js$/, use: [ &#123; loader: path.resolve('path/to/loader.js'), options: &#123; /* ... */ &#125;, &#125;, ], &#125;, ], &#125;, &#125;; From the above, we can understand how loaders are used. But this only scratches the surface. What does a specific loader look like? For example, a simple loader could be like this: module.exports = function (content) &#123; // content is the source content string passed in return content &#125; A loader is just a node module exposing a function that can only receive one parameter: a string containing the content of the resource file. The function’s return value is the processed content. Creating a Custom Webpack Loader Guidelines for Using Custom Loaders When writing loaders, you should follow these guidelines. They are listed in order of importance, and some apply only to specific scenarios. Please read the detailed sections below for more information. Keep it simple. Use chaining. Output should be modular. Ensure it’s stateless. Use loader utilities. Record loader dependencies. Resolve module dependencies. Extract common code. Avoid absolute paths. Use peer dependencies. Step 1: Create Project Directory and Files First, create the following files in a folder within your webpack project directory: src/loader/custom-loader.js: The source file for your custom loader. src/index.js: JavaScript entry file for testing the custom loader. Step 2: Write the Custom Loader In the custom-loader.js file, write your custom loader code. This loader adds a comment at the top of each loaded JavaScript file. // src/loader/custom-loader.js module.exports = function(source) &#123; // Add a custom comment at the top of the source code const updatedSource = `/** Custom Comment added by Custom Loader */\\n$&#123;source&#125;`; return updatedSource; &#125;; Step 3: Configure Webpack Create a Webpack configuration file webpack.config.js in the project root directory. Use the custom loader you just created in the configuration file. // webpack.config.js const path = require('path'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist'), &#125;, module: &#123; rules: [ &#123; test: /\\.js$/, use: ['custom-loader'], // Use the custom loader to process .js files exclude: /node_modules/, &#125;, ], &#125;, &#125;; This configuration achieves a simple functionality. Now let’s discuss how to test the local loader. There are two ways to do this: one is through Npm link for testing, a convenient method where you can create a symbolic link for local testing. Here is a link to npm-link. Another way is to configure the path directly in the project: Single Loader Configuration // webpack.config.js &#123; test: /\\.js$/ use: [ &#123; loader: path.resolve('path/to/custom-loader.js'), options: &#123;/* ... */&#125; &#125; ] &#125; Multiple Loader Configuration You can also configure it using an array: // webpack.config.js resolveLoader: &#123; // Look for loaders first in the node_modules directory; if not found, search in the loaders directory modules: [ 'node_modules', path.resolve(__dirname, 'custom-loader') ] &#125; Step 4: Test the Custom Loader In the index.js file, write some JavaScript code, for example: // src/index.js console.log('Hello, Webpack Loader!'); Step 5: Run Webpack Build Run the following command to build your project: npx webpack --config webpack.config.js After the build is complete, you will find the generated bundle.js file in the dist folder. In this file, you can see JavaScript code with a custom comment added at the top. ## Simple Usage of Webpack Plugin Plugins provide complete control over the webpack engine for third-party developers. By introducing custom behaviors into the webpack build process through stage-based build callbacks, developers can customize webpack&#39;s behavior. Here&#39;s the simplest example: &#96;&#96;&#96;javascript &#x2F;&#x2F; webpack.config.js const HtmlWebpackPlugin &#x3D; require(&#39;html-webpack-plugin&#39;); module.exports &#x3D; &#123; entry: &#39;.&#x2F;src&#x2F;index.js&#39;, output: &#123; filename: &#39;bundle.js&#39;, path: __dirname + &#39;&#x2F;dist&#39;, &#125;, plugins: [ new HtmlWebpackPlugin(&#123; template: &#39;.&#x2F;src&#x2F;index.html&#39;, &#x2F;&#x2F; Specify the HTML template file filename: &#39;index.html&#39;, &#x2F;&#x2F; Generated HTML file name &#125;), &#x2F;&#x2F; You can add more plugins here ], &#125;; In this example, the HtmlWebpackPlugin is used. It generates a new HTML file based on the specified HTML template and automatically adds the bundled JavaScript file to the generated HTML file. A basic webpack plugin consists of the following components: A JavaScript named function or JavaScript class. Define an apply method on the plugin function’s prototype. The apply method is called when webpack loads the plugin and is passed the compiler object. Specify an event hook bound to webpack itself. Process specific data from webpack’s internal instances. Call the callback provided by webpack after the functionality is completed. A plugin structure looks like this: class HelloWorldPlugin &#123; apply(compiler) &#123; compiler.hooks.done.tap( 'Hello World Plugin', ( stats /* After binding the done hook, stats is passed as a parameter. */ ) => &#123; console.log('Hello World!'); &#125; ); &#125; &#125; module.exports = HelloWorldPlugin; Compiler and Compilation The two most important resources in plugin development are the compiler and compilation objects. Plugin development revolves around hooks on these objects. The compiler object is essentially bound to the entire webpack environment. It contains all the environment configurations, including options, loaders, and plugins. When webpack starts, this object is instantiated and it is globally unique. The parameters passed into the apply method are properties of this object. The compilation object is created each time resources are built. It represents the current module resources, compiled generated resources, changed files, and tracked dependency status. It also provides many hooks. Creating a Custom Webpack Plugin Step 1: Create Project Directory and Files First, create the following file in a folder within your webpack project directory: src/plugins/CustomPlugin.js: Source file for your custom plugin. Step 2: Write the Custom Plugin In the CustomPlugin.js file, write a plugin that outputs a message when the webpack build process is completed. // src/plugins/CustomPlugin.js class CustomPlugin &#123; apply(compiler) &#123; compiler.hooks.done.tap('CustomPlugin', () => &#123; console.log('CustomPlugin: Webpack build process is done!'); &#125;); &#125; &#125; module.exports = CustomPlugin; Step 3: Configure Webpack In the configuration file, use the custom plugin you just created. // webpack.config.js const CustomPlugin = require('./src/plugins/CustomPlugin'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: __dirname + '/dist', &#125;, plugins: [ new CustomPlugin(), // You can add more plugins here ], &#125;; Step 4: Run Webpack Build Now, run the webpack build: npx webpack --config webpack.config.js","link":"/2023/10/29/en/webpack-plugin-design/"},{"title":"Vue Shallow Reactivity vs Deep Reactivity","text":"Introduction Explore the differences between reactive and shallowReactive, delving into the concepts of deep reactivity and shallow reactivity in Vue.js. Shallow Reactivity vs Deep Reactivity const obj = reactive(&#123; foo: &#123; bar: 1 &#125; &#125;) effect(() =>&#123; console.log(obj.foo.bar) &#125;) // Modifying obj.foo.bar value does not trigger reactivity obj.foo.bar = 2 Initially, an object obj is created with a property foo containing another object &#123; bar: 1 &#125;. When accessing obj.foo.bar inside an effect function, it is noticed that modifying obj.foo.bar does not trigger the effect function again. Why does this happen? Let’s take a look at the current implementation: function reactive(obj) &#123; return new Proxy(obj ,&#123; get(target, key, receiver) &#123; if (key === 'raw') return target; track(target, key); // When reading the property value, return it directly return Reflect.get(target, key, receiver) &#125; // Other trapping functions are omitted &#125;) &#125; In the given code, when accessing obj.foo.bar, it first reads the value of obj.foo. Here, Reflect.get is used to directly return the result of obj.foo. Since the result obtained through Reflect.get is a plain object, namely &#123; bar: 1 &#125;, it is not a reactive object. Therefore, when accessing obj.foo.bar inside the effect function, no reactivity is established. To address this, the result returned by Reflect.get needs to be wrapped: function reactive(obj) &#123; return new Proxy(obj, &#123; get(target, key, receiver) &#123; const result = Reflect.get(target, key, receiver); // If the result is an object, make it reactive if (typeof result === 'object') &#123; return reactive(result); &#125; return result; &#125;, // Other traps... &#125;); &#125; In this code snippet, the reactive function is defined. It takes an object as a parameter and returns a proxy of that object. The proxy uses a get trap function that triggers when accessing a property of the object. In the get trap, Reflect.get is used to retrieve the property value. If the result is an object, it is made reactive by calling the reactive function recursively. This ensures that nested objects also possess reactive properties, allowing modifications to trigger the reactivity system. Shallow Reactivity However, there are scenarios where deep reactivity is not desired, leading to the concept of shallowReactive or shallow reactivity. Shallow reactivity means that only the top-level properties of an object are reactive. For example: Suppose we have an object with a nested object as its property: let obj = &#123; innerObj: &#123; key: 'value' &#125; &#125; If we apply deep reactivity to obj: let reactiveObj = reactive(obj); Any modifications to obj or innerObj properties will trigger the reactivity system: reactiveObj.innerObj.key = 'new value'; // Triggers reactivity However, if we want only the top-level properties of obj to be reactive, meaning modifications to obj trigger reactivity but modifications to innerObj do not, we use the shallowReactive function: let shallowReactiveObj = shallowReactive(obj); With shallowReactive, only modifications to obj will trigger reactivity: shallowReactiveObj.innerObj = &#123;&#125;; // Triggers reactivity shallowReactiveObj.innerObj.key = 'new value'; // Does not trigger reactivity Vue.js and reactive vs shallowReactive In Vue.js, both reactive and shallowReactive functions are used to create reactive objects. Let’s explore their differences. The reactive function creates deeply reactive objects. This means that both the object itself and all its nested objects become reactive. Any modifications to the object or its nested objects’ properties will trigger the reactivity system. On the other hand, the shallowReactive function creates shallowly reactive objects. This means that only the top-level properties of the object are reactive. If the object contains nested objects, modifications to those nested objects’ properties will not trigger the reactivity system. let obj = &#123; innerObj: &#123; key: 'value' &#125; &#125; let reactiveObj = Vue.reactive(obj); reactiveObj.innerObj.key = ‘new value’; // Triggers reactivity let shallowReactiveObj = Vue.shallowReactive(obj); shallowReactiveObj.innerObj.key = ‘new value’; // Does not trigger reactivity Readonly and Shallow Readonly After discussing reactivity and shallow reactivity, let’s talk about readonly and shallow readonly: Vue.js provides readonly and shallowReadonly functions to create readonly reactive objects. The readonly function creates deeply readonly reactive objects. This means that both the object itself and all its nested objects are readonly. Any attempts to modify the object or its nested objects’ properties will fail. The shallowReadonly function creates shallow readonly reactive objects. This means that only the top-level properties of the object are readonly. If the object contains nested objects, properties of these nested objects can be modified. let obj = &#123; innerObj: &#123; key: 'value' &#125; &#125; let readonlyObj = Vue.readonly(obj); readonlyObj.innerObj.key = 'new value'; // This will fail because the object is readonly let shallowReadonlyObj = Vue.shallowReadonly(obj); shallowReadonlyObj.innerObj.key = 'new value'; // This will succeed because only top-level properties are readonly","link":"/2023/11/01/en/vue-reactive-shallowReactive/"}],"tags":[{"name":"http","slug":"http","link":"/en/tags/http/"},{"name":"Webpack","slug":"Webpack","link":"/en/tags/Webpack/"},{"name":"Build","slug":"Build","link":"/en/tags/Build/"},{"name":"Ajax","slug":"Ajax","link":"/en/tags/Ajax/"},{"name":"JavaScript","slug":"JavaScript","link":"/en/tags/JavaScript/"},{"name":"Front-end","slug":"Front-end","link":"/en/tags/Front-end/"},{"name":"Vue","slug":"Vue","link":"/en/tags/Vue/"}],"categories":[{"name":"http","slug":"http","link":"/en/categories/http/"},{"name":"Webpack","slug":"Webpack","link":"/en/categories/Webpack/"},{"name":"Build","slug":"Build","link":"/en/categories/Build/"},{"name":"Front-end","slug":"Front-end","link":"/en/categories/Front-end/"},{"name":"Vue","slug":"Vue","link":"/en/categories/Vue/"}]}