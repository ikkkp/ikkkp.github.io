<!DOCTYPE html>
<html class="has-navbar-fixed-top" lang="en">
<head>
    <meta charset="utf-8">
<title>Category: Cloud-Computing - Huangzl&#39;s blog</title>
<meta name="viewport" content="width=device-width, initial-scale=1">



            
<link href="https://ikkkp.github.io/categories/Hadoop/Cloud-Computing/" rel="alternate" hreflang="zh-TW" />
            
    


    
    <meta name="description" content="A tech blog about frotn-end and security">   
    



    
<link rel="canonical" href="https://ikkkp.github.io/en/categories/Hadoop/Cloud-Computing/">
    





    <meta property="og:type" content="website">
<meta property="og:title" content="Huangzl&#39;s blog">
<meta property="og:url" content="https://ikkkp.github.io/en/categories/Hadoop/Cloud-Computing/index.html">
<meta property="og:site_name" content="Huangzl&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Huangzl">
<meta name="twitter:card" content="summary_large_image">



<link rel="alternative" href="/atom.xml" title="Huangzl&#39;s blog" type="application/atom+xml">



<link rel="icon" href="/img/IK.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">


<link rel="stylesheet" href="/css/bulma.css?v=2.css">



<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" />


<link rel="stylesheet" href="/css/style.css?v=4.css">





    
    
    
    
    
    
    
    
    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1393J2EVCZ"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-1393J2EVCZ');
</script>


    


<meta name="generator" content="Hexo 6.3.0"></head>
<body>
    <script>
        if (localStorage.getItem('dark-mode')) {
            if (localStorage.getItem('dark-mode') === 'true') {
                document.body.classList.add('dark-mode')
            }
        } else {
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                document.body.classList.add('dark-mode')
            }
        }
    </script>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/en">
                
                    
                    Huangzl&#39;s blog
                    
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/en/archives">Archive</a>
            
            <a class="navbar-item "
               href="/en/categories">Categories</a>
            
            <a class="navbar-item "
               href="/en/abouts">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            
            
            <a class="navbar-item" target="_blank" title="Twitter" href="https://twitter.com/hungzln3">
                
                <i class="fab fa-twitter"></i>
                
            </a>
               
            <a class="navbar-item" target="_blank" title="RSS" href="/atom-en.xml">
                
                <i class="fas fa-rss"></i>
                
            </a>
               
            
            <a class="navbar-item btn-dark-mode" title="dark-mode" href="#">
                <div>
                    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="15" height="15" viewBox="0 0 256 256" xml:space="preserve">
                    <defs>
                    </defs>
                    <g style="stroke: none; stroke-width: 0; stroke-dasharray: none; stroke-linecap: butt; stroke-linejoin: miter; stroke-miterlimit: 10; fill: none; fill-rule: nonzero; opacity: 1;" transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)" >
                        <path d="M 87.823 60.7 c -0.463 -0.423 -1.142 -0.506 -1.695 -0.214 c -15.834 8.398 -35.266 2.812 -44.232 -12.718 c -8.966 -15.53 -4.09 -35.149 11.101 -44.665 c 0.531 -0.332 0.796 -0.963 0.661 -1.574 c -0.134 -0.612 -0.638 -1.074 -1.259 -1.153 c -9.843 -1.265 -19.59 0.692 -28.193 5.66 C 13.8 12.041 6.356 21.743 3.246 33.35 S 1.732 57.08 7.741 67.487 c 6.008 10.407 15.709 17.851 27.316 20.961 C 38.933 89.486 42.866 90 46.774 90 c 7.795 0 15.489 -2.044 22.42 -6.046 c 8.601 -4.966 15.171 -12.43 18.997 -21.586 C 88.433 61.79 88.285 61.123 87.823 60.7 z" style="stroke: none; stroke-width: 1; stroke-dasharray: none; stroke-linecap: butt; stroke-linejoin: miter; stroke-miterlimit: 10; fill: #ffa716; fill-rule: nonzero; opacity: 1;" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round" />
                    </g>
                    </svg>
                </div>
            </a>
            
               <a class="navbar-item" href="/categories/Hadoop/Cloud-Computing/">中文</a>
            
            

        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5><i class="far fa-folder"></i>Cloud-Computing</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2023/11/08/en/hadoop-2/" itemprop="url">MapReduce Working Principle in Hadoop</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2023-11-08T07:48:11.000Z" itemprop="datePublished">8 November 2023</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Hadoop/">Hadoop</a><span>></span><a class="article-category-link" href="/en/categories/Hadoop/Cloud-Computing/">Cloud-Computing</a>
        </span>
        
        
        
        <spen data-nosnippet class="column is-narrow">(Translated by ChatGPT)</span>
        
    </div>
    
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <h2><span id="definition-of-mapreduce">Definition of MapReduce</span></h2><p>MapReduce is a programming framework for distributed computing programs. It is the core framework for developing “Hadoop-based data analysis applications”. Its core function is to integrate the user’s written business logic code and default components into a complete distributed computing program, which runs concurrently on a Hadoop cluster.</p>
<h2><span id="reason-for-the-emergence-of-mapreduce">Reason for the Emergence of MapReduce</span></h2><p>Why do we need MapReduce?</p>
<ul>
<li>Massive data cannot be processed on a single machine due to hardware resource limitations.</li>
<li>Once the single-machine version of the program is extended to run on a cluster, it will greatly increase the complexity and development difficulty of the program.</li>
<li>With the introduction of the MapReduce framework, developers can focus most of their work on the development of business logic, while leaving the complexity of distributed computing to the framework to handle.</li>
</ul>
<p>Consider a word count requirement in a scenario with massive data:</p>
<ul>
<li>Single-machine version: limited memory, limited disk, limited computing power</li>
<li>Distributed: file distributed storage (HDFS), computing logic needs to be divided into at least two stages (one stage is independently concurrent, one stage is converged), how to distribute computing programs, how to allocate computing tasks (slicing), how to start the two-stage program? How to coordinate? Monitoring during the entire program running process? Fault tolerance? Retry?</li>
</ul>
<p>It can be seen that when the program is extended from a single-machine version to a distributed version, a large amount of complex work will be introduced.</p>
<h2><span id="relationship-between-mapreduce-and-yarn">Relationship between MapReduce and Yarn</span></h2><p>Yarn is a resource scheduling platform that is responsible for providing server computing resources for computing programs, which is equivalent to a distributed operating system platform. MapReduce and other computing programs are like application programs running on top of the operating system.</p>
<p>Important concepts of YARN:</p>
<ol>
<li>Yarn does not know the running mechanism of the program submitted by the user;</li>
<li>Yarn only provides scheduling of computing resources (when the user program applies for resources from Yarn, Yarn is responsible for allocating resources);</li>
<li>The supervisor role in Yarn is called ResourceManager;</li>
<li>The role that specifically provides computing resources in Yarn is called NodeManager;</li>
<li>In this way, Yarn is completely decoupled from the running user program, which means that various types of distributed computing programs (MapReduce is just one of them), such as MapReduce, storm programs, spark programs, tez, etc., can run on Yarn;</li>
<li>Therefore, computing frameworks such as Spark and Storm can be integrated to run on Yarn, as long as they have resource request mechanisms that comply with Yarn specifications in their respective frameworks;</li>
<li>Yarn becomes a universal resource scheduling platform. From then on, various computing clusters that previously existed in enterprises can be integrated on a physical cluster to improve resource utilization and facilitate data sharing.</li>
</ol>
<h2><span id="mapreduce-working-principle">MapReduce Working Principle</span></h2><p>Strictly speaking, MapReduce is not an algorithm, but a computing idea. It consists of two stages: map and reduce.</p>
<h3><span id="mapreduce-process">MapReduce Process</span></h3><p>To improve development efficiency, common functions in distributed programs can be encapsulated into frameworks, allowing developers to focus on business logic.</p>
<p>MapReduce is such a general framework for distributed programs, and its overall structure is as follows (there are three types of instance processes during distributed operation):</p>
<ul>
<li>MRAppMaster: responsible for the process scheduling and status coordination of the entire program</li>
<li>MapTask: responsible for the entire data processing process of the map phase</li>
<li>ReduceTask: responsible for the entire data processing process of the reduce phase</li>
</ul>
<h3><span id="mapreduce-mechanism">MapReduce Mechanism</span></h3><p><img src="/img/hadoop/hadoop3.png" alt="hadoop"></p>
<p>The process is described as follows:</p>
<ol>
<li><p>When an MR program starts, the MRAppMaster is started first. After the MRAppMaster starts, according to the description information of this job, it calculates the number of MapTask instances required and applies to the cluster to start the corresponding number of MapTask processes.</p>
</li>
<li><p>After the MapTask process is started, data processing is performed according to the given data slice range. The main process is:</p>
</li>
</ol>
<ul>
<li>Use the inputformat specified by the customer to obtain the RecordReader to read the data and form input KV pairs;</li>
<li>Pass the input KV pairs to the customer-defined map() method for logical operation, and collect the KV pairs output by the map() method to the cache;</li>
<li>Sort the KV pairs in the cache according to K partition and continuously overflow to the disk file.</li>
</ul>
<ol start="3">
<li><p>After the MRAppMaster monitors that all MapTask process tasks are completed, it will start the corresponding number of ReduceTask processes according to the customer-specified parameters, and inform the ReduceTask process of the data range (data partition) to be processed.</p>
</li>
<li><p>After the ReduceTask process is started, according to the location of the data to be processed notified by the MRAppMaster, it obtains several MapTask output result files from several machines where the MapTask is running, and performs re-merging and sorting locally. Then, groups the KV with the same key into one group, calls the customer-defined reduce() method for logical operation, collects the result KV output by the operation, and then calls the customer-specified outputformat to output the result data to external storage.</p>
</li>
</ol>
<p>Let’s take an example.</p>
<p><img src="/img/hadoop/hadoop4.webp" alt="hadoop"><br>The above figure shows a word frequency counting task.</p>
<ol>
<li><p>Hadoop divides the input data into several slices and assigns each split to a map task for processing.</p>
</li>
<li><p>After mapping, each word and its frequency in this task are obtained.</p>
</li>
<li><p>Shuffle puts the same words together, sorts them, and divides them into several slices.</p>
</li>
<li><p>According to these slices, reduce is performed.</p>
</li>
<li><p>The result of the reduce task is counted and output to a file.</p>
</li>
</ol>
<p>In MapReduce, two roles are required to complete these processes: JobTracker and TaskTracker.</p>
<p><img src="/img/hadoop/hadoop5.webp" alt="hadoop"></p>
<p>JobTracker is used to schedule and manage other TaskTrackers. JobTracker can run on any computer in the cluster. TaskTracker is responsible for executing tasks and must run on DataNode.</p>
<p><img src="/img/hadoop/hadoop6.png" alt="hadoop"></p>
<p>In the entire Hadoop architecture, the computing framework plays a crucial role, on the one hand, it can operate on the data in HDFS, on the other hand, it can be encapsulated to provide calls from upper-level components such as Hive and Pig.</p>
<p>Let’s briefly introduce some of the more important components.</p>
<p>HBase: originated from Google’s BigTable; it is a highly reliable, high-performance, column-oriented, and scalable distributed database.</p>
<p>Hive: is a data warehouse tool that can map structured data files to a database table, and quickly implement simple MapReduce statistics through SQL-like statements, without the need to develop dedicated MapReduce applications, which is very suitable for statistical analysis of data warehouses.</p>
<p>Pig: is a large-scale data analysis tool based on Hadoop. It provides a SQL-LIKE language called Pig Latin. The compiler of this language converts SQL-like data analysis requests into a series of optimized MapReduce operations.</p>
<p>ZooKeeper: originated from Google’s Chubby; it is mainly used to solve some data management problems frequently encountered in distributed applications, simplifying the difficulty of coordinating and managing distributed application.</p>
<p>Ambari: Hadoop management tool, which can monitor, deploy, and manage clusters quickly.</p>
<p>Sqoop: used to transfer data between Hadoop and traditional databases.</p>
<p>Mahout: an extensible machine learning and data mining library.</p>
<p>Advantages and Applications of Hadoop</p>
<p>Overall, Hadoop has the following advantages:</p>
<p>High reliability: This is determined by its genes. Its genes come from Google. The best thing Google is good at is “garbage utilization.” When Google started, it was poor and couldn’t afford high-end servers, so it especially likes to deploy this kind of large system on ordinary computers. Although the hardware is unreliable, the system is very reliable.</p>
<p>High scalability: Hadoop distributes data and completes computing tasks among available computer clusters, and these clusters can be easily expanded. In other words, it is easy to become larger.</p>
<p>High efficiency: Hadoop can dynamically move data between nodes and ensure dynamic balance of each node, so the processing speed is very fast.</p>
<p>High fault tolerance: Hadoop can automatically save multiple copies of data and automatically redistribute failed tasks. This is also considered high reliability.</p>
<p>Low cost: Hadoop is open source and relies on community services, so the cost of use is relatively low.</p>
<p>Based on these advantages, Hadoop is suitable for applications in large data storage and large data analysis, suitable for running on clusters of several thousand to tens of thousands of servers, and supports PB-level storage capacity.</p>
<p>Hadoop’s applications are very extensive, including: search, log processing, recommendation systems, data analysis, video and image analysis, data storage, etc., can be deployed using it.</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2023/11/08/en/hadoop-1/" itemprop="url">Understanding Hadoop in One Article</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2023-11-08T07:12:04.000Z" itemprop="datePublished">8 November 2023</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Hadoop/">Hadoop</a><span>></span><a class="article-category-link" href="/en/categories/Hadoop/Cloud-Computing/">Cloud-Computing</a>
        </span>
        
        
        
        <spen data-nosnippet class="column is-narrow">(Translated by ChatGPT)</span>
        
    </div>
    
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <h2><span id="what-is-hadoop">What is Hadoop?</span></h2><p>Hadoop is a distributed system infrastructure developed by the Apache Foundation. It is a software framework that combines a storage system and a computing framework. It mainly solves the problem of storing and computing massive data and is the cornerstone of big data technology. Hadoop processes data in a reliable, efficient, and scalable way. Users can develop distributed programs on Hadoop without understanding the underlying details of the distributed system. Users can easily develop and run applications that process massive data on Hadoop.</p>
<h2><span id="what-problems-can-hadoop-solve">What problems can Hadoop solve?</span></h2><ul>
<li><p><strong>Massive data storage</strong></p>
<p>HDFS has high fault tolerance and is designed to be deployed on low-cost hardware. It provides high throughput for accessing data and is suitable for applications with large data sets. It consists of n machines running DataNode and one machine running NameNode (another standby). Each DataNode manages a portion of the data, and NameNode is responsible for managing the information (metadata) of the entire HDFS cluster.</p>
</li>
<li><p><strong>Resource management, scheduling, and allocation</strong></p>
<p><code>Apache Hadoop YARN</code> (Yet Another Resource Negotiator) is a new Hadoop resource manager. It is a general resource management system and scheduling platform that provides unified resource management and scheduling for upper-layer applications. Its introduction has brought huge benefits to the cluster in terms of utilization, unified resource management, and data sharing.</p>
</li>
</ul>
<h2><span id="the-origin-of-hadoop">The origin of Hadoop</span></h2><p><img src="/img/hadoop/hadoop1.png" alt="hadoop"></p>
<h2><span id="the-core-architecture-of-hadoop">The core architecture of Hadoop</span></h2><p>The core of Hadoop is HDFS and MapReduce. HDFS provides storage for massive data, and MapReduce provides a computing framework for massive data.</p>
<h3><span id="hdfs">HDFS</span></h3><p><img src="/img/hadoop/hadoop2.png" alt="hadoop"></p>
<p>The entire HDFS has three important roles: <strong>NameNode</strong>, <strong>DataNode</strong>, and <strong>Client</strong>.</p>
<p>Typical master-slave architecture, using TCP&#x2F;IP communication.</p>
<ul>
<li><p><strong>NameNode:</strong> The master node of the distributed file system, responsible for managing the namespace of the file system, cluster configuration information, and storage block replication. The NameNode stores the metadata of the file system in memory, including file information, block information for each file, and information about each block in the DataNode.</p>
</li>
<li><p><strong>DataNode:</strong> The slave node of the distributed file system, which is the basic unit of file storage. It stores blocks in the local file system and saves the metadata of the blocks. It also periodically sends information about all existing blocks to the NameNode.</p>
</li>
<li><p><strong>Client:</strong> Splits files, accesses HDFS, interacts with the NameNode to obtain file location information, and interacts with the DataNode to read and write data.</p>
</li>
</ul>
<p>There is also the concept of a block: a block is the basic read and write unit in HDFS. Files in HDFS are stored as blocks, which are replicated to multiple DataNodes. The size of a block (usually 64MB) and the number of replicated blocks are determined by the client when the file is created.</p>
<h3><span id="mapreduce">MapReduce</span></h3><p>MapReduce is a distributed computing model that divides large data sets (greater than 1TB) into many small data blocks, and then performs parallel processing on various nodes in the cluster, and finally aggregates the results. The MapReduce calculation process can be divided into two stages: the Map stage and the Reduce stage.</p>
<ul>
<li><p><strong>Map stage:</strong> The input data is divided into several small data blocks, and then multiple Map tasks process them in parallel. Each Map task outputs the processing result as several key-value pairs.</p>
</li>
<li><p><strong>Reduce stage:</strong> The output results of the Map stage are grouped according to the keys in the key-value pairs, and then multiple Reduce tasks process them in parallel. Each Reduce task outputs the processing result as several key-value pairs.</p>
</li>
</ul>
<h2><span id="summary">Summary</span></h2><p>Hadoop is a distributed system infrastructure that mainly solves the problem of storing and computing massive data. Its core is HDFS and MapReduce, where HDFS provides storage for massive data, and MapReduce provides a computing framework for massive data. In addition, Hadoop also has an important component-YARN, which is a general resource management system and scheduling platform that provides unified resource management and scheduling for upper-layer applications.</p>

    
    </div>
    
    
</article>




    
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 Huangzl&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ikkkp">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>English</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu" style="top:100%">
            <div class="dropdown-content">
            <!-- NOTE: 永遠回到首頁 -->
            
                <a href="/categories/Hadoop/Cloud-Computing/" class="dropdown-item">
                    中文
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.6.3/jquery.min.js"></script>



    
    
    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js?v=3.js"></script>


    
</body>
</html>